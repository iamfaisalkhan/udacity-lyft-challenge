{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('../../')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage.io import imread\n",
    "\n",
    "from gen.load_data import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               image                   id  \\\n",
      "0  ../../data/Train/CameraRGB/episode_0002_000287...  episode_0002_000287   \n",
      "1  ../../data/Train/CameraRGB/episode_0008_000112...  episode_0008_000112   \n",
      "2                 ../../data/Train/CameraRGB/804.png                  804   \n",
      "3  ../../data/Train/CameraRGB/episode_0008_000286...  episode_0008_000286   \n",
      "4  ../../data/Train/CameraRGB/episode_0003_000261...  episode_0003_000261   \n",
      "\n",
      "                                               label  \n",
      "0  ../../data/Train/CameraSeg/episode_0002_000287...  \n",
      "1  ../../data/Train/CameraSeg/episode_0008_000112...  \n",
      "2                 ../../data/Train/CameraSeg/804.png  \n",
      "3  ../../data/Train/CameraSeg/episode_0008_000286...  \n",
      "4  ../../data/Train/CameraSeg/episode_0003_000261...  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "train_df, valid_df, test_df = load_data('../../data')\n",
    "\n",
    "\n",
    "print(train_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/faisal/anaconda3/envs/ai/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 320, 416, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 320, 416, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 320, 416, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 160, 208, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 160, 208, 128 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 160, 208, 128 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 80, 104, 128) 0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 80, 104, 256) 295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 80, 104, 256) 590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 80, 104, 256) 590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 40, 52, 256)  0           block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 40, 52, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 40, 52, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 40, 52, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 20, 26, 512)  0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 20, 26, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 20, 26, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 20, 26, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)      (None, 10, 13, 512)  0           block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 20, 26, 512)  2359808     block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 20, 26, 1024) 0           conv2d_transpose_1[0][0]         \n",
      "                                                                 block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 20, 26, 512)  4719104     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 20, 26, 256)  1179904     conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 40, 52, 256)  590080      conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 40, 52, 256)  1024        block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 40, 52, 512)  0           conv2d_transpose_2[0][0]         \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 40, 52, 256)  1179904     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 40, 52, 128)  295040      conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 80, 104, 128) 147584      conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 80, 104, 128) 512         block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 80, 104, 256) 0           conv2d_transpose_3[0][0]         \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 80, 104, 128) 295040      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 80, 104, 64)  73792       conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 160, 208, 64) 36928       conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 160, 208, 64) 256         block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 160, 208, 128 0           conv2d_transpose_4[0][0]         \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 160, 208, 64) 73792       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 160, 208, 3)  195         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTrans (None, 320, 416, 3)  84          conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "y_ (Activation)                 (None, 320, 416, 3)  0           conv2d_transpose_5[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 25,667,735\n",
      "Trainable params: 25,666,839\n",
      "Non-trainable params: 896\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from models.unet import model_unetVGG16\n",
    "\n",
    "model = model_unetVGG16(3, image_shape=(320, 416, 3), keep_prob=0.5)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from gen.datagen import oversample_generator_from_df, balanced_generator_from_df\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "model_dir = '../../saved_models/unet/unet_v3/'\n",
    "\n",
    "if not os.path.exists(model_dir):\n",
    "    os.mkdir(model_dir)\n",
    "\n",
    "train_gen = oversample_generator_from_df(train_df, BATCH_SIZE, (320, 416))\n",
    "valid_gen = balanced_generator_from_df(valid_df, BATCH_SIZE, (320, 416))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "67/67 [==============================] - 95s 1s/step - loss: 0.2227 - acc: 0.9245 - val_loss: 0.2472 - val_acc: 0.9249\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.24721, saving model to ../../saved_models/unet/unet_v3//model.hdf5\n",
      "Epoch 2/500\n",
      "67/67 [==============================] - 36s 543ms/step - loss: 0.0686 - acc: 0.9773 - val_loss: 0.1146 - val_acc: 0.9637\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.24721 to 0.11455, saving model to ../../saved_models/unet/unet_v3//model.hdf5\n",
      "Epoch 3/500\n",
      "67/67 [==============================] - 37s 550ms/step - loss: 0.0430 - acc: 0.9851 - val_loss: 0.1663 - val_acc: 0.9638\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/500\n",
      "67/67 [==============================] - 37s 551ms/step - loss: 0.0306 - acc: 0.9890 - val_loss: 0.0603 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.11455 to 0.06035, saving model to ../../saved_models/unet/unet_v3//model.hdf5\n",
      "Epoch 5/500\n",
      "67/67 [==============================] - 37s 551ms/step - loss: 0.0251 - acc: 0.9907 - val_loss: 0.1174 - val_acc: 0.9614\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 6/500\n",
      "67/67 [==============================] - 37s 550ms/step - loss: 0.0299 - acc: 0.9901 - val_loss: 0.0827 - val_acc: 0.9781\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 7/500\n",
      "67/67 [==============================] - 37s 551ms/step - loss: 0.0303 - acc: 0.9903 - val_loss: 0.3614 - val_acc: 0.9398\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 8/500\n",
      "67/67 [==============================] - 37s 549ms/step - loss: 0.0312 - acc: 0.9893 - val_loss: 0.0554 - val_acc: 0.9859\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.06035 to 0.05538, saving model to ../../saved_models/unet/unet_v3//model.hdf5\n",
      "Epoch 9/500\n",
      "67/67 [==============================] - 37s 553ms/step - loss: 0.0214 - acc: 0.9923 - val_loss: 0.0398 - val_acc: 0.9875\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.05538 to 0.03981, saving model to ../../saved_models/unet/unet_v3//model.hdf5\n",
      "Epoch 10/500\n",
      "67/67 [==============================] - 37s 550ms/step - loss: 0.0176 - acc: 0.9933 - val_loss: 0.0419 - val_acc: 0.9869\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "Epoch 11/500\n",
      "67/67 [==============================] - 37s 551ms/step - loss: 0.0183 - acc: 0.9934 - val_loss: 0.0508 - val_acc: 0.9859\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "Epoch 12/500\n",
      "67/67 [==============================] - 37s 550ms/step - loss: 0.0228 - acc: 0.9929 - val_loss: 0.0392 - val_acc: 0.9879\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.03981 to 0.03922, saving model to ../../saved_models/unet/unet_v3//model.hdf5\n",
      "Epoch 13/500\n",
      "67/67 [==============================] - 37s 554ms/step - loss: 0.0212 - acc: 0.9927 - val_loss: 0.0876 - val_acc: 0.9741\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      "Epoch 14/500\n",
      "67/67 [==============================] - 37s 552ms/step - loss: 0.0187 - acc: 0.9934 - val_loss: 0.0521 - val_acc: 0.9850\n",
      "\n",
      "Epoch 00014: val_loss did not improve\n",
      "Epoch 15/500\n",
      "67/67 [==============================] - 37s 553ms/step - loss: 0.0206 - acc: 0.9937 - val_loss: 0.0396 - val_acc: 0.9879\n",
      "\n",
      "Epoch 00015: val_loss did not improve\n",
      "Epoch 16/500\n",
      "67/67 [==============================] - 37s 551ms/step - loss: 0.0172 - acc: 0.9941 - val_loss: 0.0585 - val_acc: 0.9859\n",
      "\n",
      "Epoch 00016: val_loss did not improve\n",
      "Epoch 17/500\n",
      "67/67 [==============================] - 37s 552ms/step - loss: 0.0133 - acc: 0.9947 - val_loss: 0.0313 - val_acc: 0.9900\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.03922 to 0.03126, saving model to ../../saved_models/unet/unet_v3//model.hdf5\n",
      "Epoch 18/500\n",
      "67/67 [==============================] - 37s 555ms/step - loss: 0.0151 - acc: 0.9945 - val_loss: 0.0456 - val_acc: 0.9876\n",
      "\n",
      "Epoch 00018: val_loss did not improve\n",
      "Epoch 19/500\n",
      "67/67 [==============================] - 37s 553ms/step - loss: 0.0148 - acc: 0.9947 - val_loss: 0.0432 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00019: val_loss did not improve\n",
      "Epoch 20/500\n",
      "67/67 [==============================] - 37s 552ms/step - loss: 0.0125 - acc: 0.9951 - val_loss: 0.0336 - val_acc: 0.9901\n",
      "\n",
      "Epoch 00020: val_loss did not improve\n",
      "Epoch 21/500\n",
      "67/67 [==============================] - 37s 553ms/step - loss: 0.0105 - acc: 0.9955 - val_loss: 0.0372 - val_acc: 0.9895\n",
      "\n",
      "Epoch 00021: val_loss did not improve\n",
      "Epoch 22/500\n",
      "67/67 [==============================] - 37s 553ms/step - loss: 0.0115 - acc: 0.9954 - val_loss: 0.0424 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00022: val_loss did not improve\n",
      "Epoch 23/500\n",
      "67/67 [==============================] - 37s 551ms/step - loss: 0.0150 - acc: 0.9948 - val_loss: 0.0584 - val_acc: 0.9828\n",
      "\n",
      "Epoch 00023: val_loss did not improve\n",
      "Epoch 24/500\n",
      "67/67 [==============================] - 37s 548ms/step - loss: 0.0266 - acc: 0.9910 - val_loss: 0.4297 - val_acc: 0.9265\n",
      "\n",
      "Epoch 00024: val_loss did not improve\n",
      "Epoch 25/500\n",
      "67/67 [==============================] - 37s 552ms/step - loss: 0.0213 - acc: 0.9925 - val_loss: 0.0996 - val_acc: 0.9775\n",
      "\n",
      "Epoch 00025: val_loss did not improve\n",
      "Epoch 26/500\n",
      "67/67 [==============================] - 37s 552ms/step - loss: 0.0124 - acc: 0.9950 - val_loss: 0.0826 - val_acc: 0.9826\n",
      "\n",
      "Epoch 00026: val_loss did not improve\n",
      "Epoch 27/500\n",
      "67/67 [==============================] - 37s 552ms/step - loss: 0.0158 - acc: 0.9949 - val_loss: 0.0503 - val_acc: 0.9875\n",
      "\n",
      "Epoch 00027: val_loss did not improve\n",
      "Epoch 28/500\n",
      "67/67 [==============================] - 37s 553ms/step - loss: 0.0167 - acc: 0.9950 - val_loss: 0.0526 - val_acc: 0.9862\n",
      "\n",
      "Epoch 00028: val_loss did not improve\n",
      "Epoch 29/500\n",
      "67/67 [==============================] - 37s 550ms/step - loss: 0.0322 - acc: 0.9905 - val_loss: 0.1136 - val_acc: 0.9767\n",
      "\n",
      "Epoch 00029: val_loss did not improve\n",
      "Epoch 30/500\n",
      "67/67 [==============================] - 37s 550ms/step - loss: 0.0179 - acc: 0.9935 - val_loss: 0.0791 - val_acc: 0.9836\n",
      "\n",
      "Epoch 00030: val_loss did not improve\n",
      "Epoch 31/500\n",
      "67/67 [==============================] - 37s 549ms/step - loss: 0.0126 - acc: 0.9950 - val_loss: 0.0658 - val_acc: 0.9851\n",
      "\n",
      "Epoch 00031: val_loss did not improve\n",
      "Epoch 32/500\n",
      "67/67 [==============================] - 37s 552ms/step - loss: 0.0122 - acc: 0.9953 - val_loss: 0.0386 - val_acc: 0.9890\n",
      "\n",
      "Epoch 00032: val_loss did not improve\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "Epoch 33/500\n",
      "67/67 [==============================] - 38s 562ms/step - loss: 0.0153 - acc: 0.9951 - val_loss: 0.0397 - val_acc: 0.9899\n",
      "\n",
      "Epoch 00033: val_loss did not improve\n",
      "Epoch 34/500\n",
      "67/67 [==============================] - 38s 563ms/step - loss: 0.0197 - acc: 0.9947 - val_loss: 0.0631 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00034: val_loss did not improve\n",
      "Epoch 35/500\n",
      "67/67 [==============================] - 38s 563ms/step - loss: 0.0141 - acc: 0.9949 - val_loss: 0.0553 - val_acc: 0.9867\n",
      "\n",
      "Epoch 00035: val_loss did not improve\n",
      "Epoch 36/500\n",
      "67/67 [==============================] - 38s 564ms/step - loss: 0.0127 - acc: 0.9953 - val_loss: 0.0328 - val_acc: 0.9894\n",
      "\n",
      "Epoch 00036: val_loss did not improve\n",
      "Epoch 37/500\n",
      "67/67 [==============================] - 38s 565ms/step - loss: 0.0104 - acc: 0.9957 - val_loss: 0.1329 - val_acc: 0.9760\n",
      "\n",
      "Epoch 00037: val_loss did not improve\n",
      "Epoch 38/500\n",
      "67/67 [==============================] - 38s 564ms/step - loss: 0.0149 - acc: 0.9952 - val_loss: 0.0494 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00038: val_loss did not improve\n",
      "Epoch 39/500\n",
      "67/67 [==============================] - 38s 568ms/step - loss: 0.0115 - acc: 0.9957 - val_loss: 0.0405 - val_acc: 0.9887\n",
      "\n",
      "Epoch 00039: val_loss did not improve\n",
      "Epoch 40/500\n",
      "67/67 [==============================] - 38s 564ms/step - loss: 0.0114 - acc: 0.9957 - val_loss: 0.0949 - val_acc: 0.9785\n",
      "\n",
      "Epoch 00040: val_loss did not improve\n",
      "Epoch 41/500\n",
      "67/67 [==============================] - 38s 564ms/step - loss: 0.0107 - acc: 0.9959 - val_loss: 0.0359 - val_acc: 0.9901\n",
      "\n",
      "Epoch 00041: val_loss did not improve\n",
      "Epoch 42/500\n",
      "67/67 [==============================] - 38s 565ms/step - loss: 0.0093 - acc: 0.9961 - val_loss: 0.0569 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00042: val_loss did not improve\n",
      "Epoch 43/500\n",
      "67/67 [==============================] - 38s 565ms/step - loss: 0.0087 - acc: 0.9962 - val_loss: 0.0323 - val_acc: 0.9914\n",
      "\n",
      "Epoch 00043: val_loss did not improve\n",
      "Epoch 44/500\n",
      "67/67 [==============================] - 38s 567ms/step - loss: 0.0100 - acc: 0.9960 - val_loss: 0.0477 - val_acc: 0.9895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00044: val_loss did not improve\n",
      "Epoch 45/500\n",
      "67/67 [==============================] - 38s 565ms/step - loss: 0.0098 - acc: 0.9960 - val_loss: 0.0331 - val_acc: 0.9911\n",
      "\n",
      "Epoch 00045: val_loss did not improve\n",
      "Epoch 46/500\n",
      "67/67 [==============================] - 38s 562ms/step - loss: 0.0089 - acc: 0.9962 - val_loss: 0.0356 - val_acc: 0.9915\n",
      "\n",
      "Epoch 00046: val_loss did not improve\n",
      "Epoch 47/500\n",
      "67/67 [==============================] - 38s 565ms/step - loss: 0.0082 - acc: 0.9964 - val_loss: 0.0379 - val_acc: 0.9913\n",
      "\n",
      "Epoch 00047: val_loss did not improve\n"
     ]
    }
   ],
   "source": [
    "from train import train_nn\n",
    "\n",
    "m = train_df.shape[0]\n",
    "history = train_nn(model, \n",
    "                   train_gen, \n",
    "                   valid_gen, \n",
    "                   training_size=67*BATCH_SIZE, \n",
    "                   batch_size=BATCH_SIZE,\n",
    "                   validation_size=valid_df.shape[0],\n",
    "                   output_path=model_dir, \n",
    "                   epochs=500,\n",
    "                   gpus = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('../../saved_models/unet/unet_v3/model.hdf5')\n",
    "model.save('../../saved_models/unet/unet_v3/model_saved.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ai]",
   "language": "python",
   "name": "conda-env-ai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
