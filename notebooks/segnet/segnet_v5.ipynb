{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('../../')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage.io import imread\n",
    "\n",
    "from gen.load_data import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               image                   id  \\\n",
      "0  ../../data/Train/CameraRGB/episode_0002_000287...  episode_0002_000287   \n",
      "1  ../../data/Train/CameraRGB/episode_0008_000112...  episode_0008_000112   \n",
      "2                 ../../data/Train/CameraRGB/804.png                  804   \n",
      "3  ../../data/Train/CameraRGB/episode_0008_000286...  episode_0008_000286   \n",
      "4  ../../data/Train/CameraRGB/episode_0014_000061...  episode_0014_000061   \n",
      "\n",
      "                                               label  \n",
      "0  ../../data/Train/CameraSeg/episode_0002_000287...  \n",
      "1  ../../data/Train/CameraSeg/episode_0008_000112...  \n",
      "2                 ../../data/Train/CameraSeg/804.png  \n",
      "3  ../../data/Train/CameraSeg/episode_0008_000286...  \n",
      "4  ../../data/Train/CameraSeg/episode_0014_000061...  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "train_df, valid_df, test_df = load_data('../../data')\n",
    "\n",
    "\n",
    "print(train_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/faisal/anaconda3/envs/ai/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 416, 544, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 416, 544, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 416, 544, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 208, 272, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 208, 272, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 208, 272, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 104, 136, 128)     0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 104, 136, 256)     295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 104, 136, 256)     590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 104, 136, 256)     590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 52, 68, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 52, 68, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 52, 68, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 52, 68, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 26, 34, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 26, 34, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 26, 34, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 26, 34, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 13, 17, 512)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 26, 34, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 26, 34, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 26, 34, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 26, 34, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 26, 34, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 26, 34, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 26, 34, 512)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 26, 34, 512)       2048      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 52, 68, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 52, 68, 256)       1179904   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 52, 68, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 52, 68, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 52, 68, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 52, 68, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 52, 68, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 52, 68, 256)       1024      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 104, 136, 256)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 104, 136, 128)     295040    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 104, 136, 128)     512       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 104, 136, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 104, 136, 128)     147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 104, 136, 128)     512       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 104, 136, 128)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 104, 136, 128)     512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2 (None, 208, 272, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 208, 272, 64)      73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 208, 272, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 208, 272, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 208, 272, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 208, 272, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 208, 272, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 208, 272, 64)      256       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2 (None, 416, 544, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 416, 544, 32)      18464     \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 416, 544, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 416, 544, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 416, 544, 32)      9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 416, 544, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 416, 544, 32)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 416, 544, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 416, 544, 3)       99        \n",
      "_________________________________________________________________\n",
      "y_ (Activation)              (None, 416, 544, 3)       0         \n",
      "=================================================================\n",
      "Total params: 21,797,347\n",
      "Trainable params: 7,076,707\n",
      "Non-trainable params: 14,720,640\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from models.segnet import model_segnetVGG16\n",
    "\n",
    "\n",
    "model = model_segnetVGG16(3, image_shape=(416, 544, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from gen.datagen import oversample_generator_from_df, balanced_generator_from_df\n",
    "\n",
    "GPUS = 2\n",
    "BATCH_SIZE = 8 * GPUS\n",
    "model_dir = '../../saved_models/segnet/segnet_v5/'\n",
    "\n",
    "if not os.path.exists(model_dir):\n",
    "    os.mkdir(model_dir)\n",
    "\n",
    "from gen.generators import gen_func, preprocess_label, preprocess_multi_label\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "\n",
    "rgb_gen = ImageDataGenerator()\n",
    "lab_gen = ImageDataGenerator()\n",
    "\n",
    "train_gen = gen_func(train_df, rgb_gen, lab_gen, image_size=(600, 800), target_size=(416, 544), batch_size = BATCH_SIZE, perturb=True)\n",
    "valid_gen = gen_func(valid_df, rgb_gen, lab_gen, image_size=(600, 800), target_size=(416, 544), batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.training_utils import multi_gpu_model\n",
    "\n",
    "model_gpu = multi_gpu_model(model, GPUS)\n",
    "\n",
    "model_gpu.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Ignore next message from keras, values are replaced anyways\n",
      "## Ignore next message from keras, values are replaced anyways\n",
      "Epoch 1/100\n",
      "Found 0 images belonging to 0 classes.\n",
      "Found 0 images belonging to 0 classes.\n",
      "Reinserting dataframe: 1683 images\n",
      "## Ignore next message from keras, values are replaced anyways\n",
      "Found 0 images belonging to 0 classes.\n",
      "Reinserting dataframe: 6159 images\n",
      "## Ignore next message from keras, values are replaced anyways\n",
      "Found 0 images belonging to 0 classes.\n",
      "Reinserting dataframe: 1683 images\n",
      "Reinserting dataframe: 6159 images\n",
      "192/192 [==============================] - 186s 967ms/step - loss: 0.1213 - acc: 0.9615 - val_loss: 0.0933 - val_acc: 0.9698\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09331, saving model to ../../saved_models/segnet/segnet_v5//model.hdf5\n",
      "Epoch 2/100\n",
      "192/192 [==============================] - 178s 925ms/step - loss: 0.0571 - acc: 0.9787 - val_loss: 0.1015 - val_acc: 0.9671\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/100\n",
      "192/192 [==============================] - 174s 908ms/step - loss: 0.0457 - acc: 0.9821 - val_loss: 0.0948 - val_acc: 0.9684\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/100\n",
      "192/192 [==============================] - 171s 893ms/step - loss: 0.0429 - acc: 0.9829 - val_loss: 0.0662 - val_acc: 0.9758\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.09331 to 0.06621, saving model to ../../saved_models/segnet/segnet_v5//model.hdf5\n",
      "Epoch 5/100\n",
      "192/192 [==============================] - 168s 875ms/step - loss: 0.0389 - acc: 0.9842 - val_loss: 0.0799 - val_acc: 0.9729\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 6/100\n",
      "192/192 [==============================] - 172s 895ms/step - loss: 0.0375 - acc: 0.9847 - val_loss: 0.0743 - val_acc: 0.9751\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 7/100\n",
      "192/192 [==============================] - 169s 879ms/step - loss: 0.0346 - acc: 0.9857 - val_loss: 0.0772 - val_acc: 0.9750\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 8/100\n",
      "192/192 [==============================] - 167s 872ms/step - loss: 0.0338 - acc: 0.9861 - val_loss: 0.0783 - val_acc: 0.9752\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "Epoch 9/100\n",
      "192/192 [==============================] - 170s 884ms/step - loss: 0.0326 - acc: 0.9864 - val_loss: 0.0687 - val_acc: 0.9755\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "Epoch 10/100\n",
      "192/192 [==============================] - 168s 875ms/step - loss: 0.0310 - acc: 0.9871 - val_loss: 0.0807 - val_acc: 0.9743\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "Epoch 11/100\n",
      "192/192 [==============================] - 171s 892ms/step - loss: 0.0298 - acc: 0.9875 - val_loss: 0.0952 - val_acc: 0.9729\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "Epoch 12/100\n",
      "192/192 [==============================] - 168s 876ms/step - loss: 0.0302 - acc: 0.9873 - val_loss: 0.0600 - val_acc: 0.9797\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.06621 to 0.05999, saving model to ../../saved_models/segnet/segnet_v5//model.hdf5\n",
      "Epoch 13/100\n",
      "192/192 [==============================] - 168s 873ms/step - loss: 0.0282 - acc: 0.9882 - val_loss: 0.0719 - val_acc: 0.9764\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      "Epoch 14/100\n",
      "192/192 [==============================] - 171s 892ms/step - loss: 0.0279 - acc: 0.9882 - val_loss: 0.0764 - val_acc: 0.9754\n",
      "\n",
      "Epoch 00014: val_loss did not improve\n",
      "Epoch 15/100\n",
      "192/192 [==============================] - 168s 874ms/step - loss: 0.0277 - acc: 0.9883 - val_loss: 0.0789 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00015: val_loss did not improve\n",
      "Epoch 16/100\n",
      "192/192 [==============================] - 170s 884ms/step - loss: 0.0275 - acc: 0.9884 - val_loss: 0.0761 - val_acc: 0.9765\n",
      "\n",
      "Epoch 00016: val_loss did not improve\n",
      "Epoch 17/100\n",
      "192/192 [==============================] - 167s 870ms/step - loss: 0.0264 - acc: 0.9888 - val_loss: 0.0863 - val_acc: 0.9739\n",
      "\n",
      "Epoch 00017: val_loss did not improve\n",
      "Epoch 18/100\n",
      "192/192 [==============================] - 168s 874ms/step - loss: 0.0266 - acc: 0.9887 - val_loss: 0.0725 - val_acc: 0.9774\n",
      "\n",
      "Epoch 00018: val_loss did not improve\n",
      "Epoch 19/100\n",
      "192/192 [==============================] - 168s 875ms/step - loss: 0.0257 - acc: 0.9891 - val_loss: 0.0844 - val_acc: 0.9755\n",
      "\n",
      "Epoch 00019: val_loss did not improve\n",
      "Epoch 20/100\n",
      "192/192 [==============================] - 171s 891ms/step - loss: 0.0261 - acc: 0.9889 - val_loss: 0.0586 - val_acc: 0.9799\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.05999 to 0.05857, saving model to ../../saved_models/segnet/segnet_v5//model.hdf5\n",
      "Epoch 21/100\n",
      "192/192 [==============================] - 170s 884ms/step - loss: 0.0249 - acc: 0.9894 - val_loss: 0.0887 - val_acc: 0.9752\n",
      "\n",
      "Epoch 00021: val_loss did not improve\n",
      "Epoch 22/100\n",
      "192/192 [==============================] - 172s 895ms/step - loss: 0.0251 - acc: 0.9893 - val_loss: 0.0723 - val_acc: 0.9780\n",
      "\n",
      "Epoch 00022: val_loss did not improve\n",
      "Epoch 23/100\n",
      " 57/192 [=======>......................] - ETA: 1:32 - loss: 0.0268 - acc: 0.9888"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-8ed7f6ca5ec1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m                    \u001b[0moutput_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                    \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                    gpus = GPUS)\n\u001b[0m",
      "\u001b[0;32m/data/udacity/lyft_challenge/train.py\u001b[0m in \u001b[0;36mtrain_nn\u001b[0;34m(model, train_gen, valid_gen, training_size, validation_size, output_path, batch_size, epochs, workers, verbose, lr, gpus)\u001b[0m\n\u001b[1;32m    157\u001b[0m                                 \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                                 \u001b[0;31m# use_multiprocessing=True,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m                                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m                                 )\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2242\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2243\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2244\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2246\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1888\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1890\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1891\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1892\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from train import train_nn\n",
    "\n",
    "m = train_df.shape[0]\n",
    "history = train_nn(model_gpu, \n",
    "                   train_gen, \n",
    "                   valid_gen, \n",
    "                   training_size=train_df.shape[0], \n",
    "                   batch_size=BATCH_SIZE,\n",
    "                   validation_size=valid_df.shape[0],\n",
    "                   output_path=model_dir, \n",
    "                   epochs=100,\n",
    "                   gpus = GPUS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gpu.load_weights('../../saved_models/segnet/segnet_v5//model.hdf5')\n",
    "# model.reset_states()\n",
    "model.save('../../saved_models/segnet/segnet_v5//model_saved.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ai]",
   "language": "python",
   "name": "conda-env-ai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
