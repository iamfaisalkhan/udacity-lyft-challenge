{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage.io import imread\n",
    "\n",
    "from gen.load_data import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  image                   id  \\\n",
      "4364  ../../data/Train/CameraRGB/episode_0006_000095...  episode_0006_000095   \n",
      "4519  ../../data/Train/CameraRGB/episode_0007_000050...  episode_0007_000050   \n",
      "4588                 ../../data/Train/CameraRGB/560.png                  560   \n",
      "4196                 ../../data/Train/CameraRGB/851.png                  851   \n",
      "3052  ../../data/Train/CameraRGB/episode_0007_000046...  episode_0007_000046   \n",
      "\n",
      "                                                  label  \n",
      "4364  ../../data/Train/CameraSeg/episode_0006_000095...  \n",
      "4519  ../../data/Train/CameraSeg/episode_0007_000050...  \n",
      "4588                 ../../data/Train/CameraSeg/560.png  \n",
      "4196                 ../../data/Train/CameraSeg/851.png  \n",
      "3052  ../../data/Train/CameraSeg/episode_0007_000046...  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "train_df, valid_df, test_df = load_data('../../data')\n",
    "\n",
    "train_df = shuffle(train_df)\n",
    "valid_df = shuffle(valid_df)\n",
    "\n",
    "print(train_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 320, 416, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 320, 416, 64) 1792        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 320, 416, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 160, 208, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 160, 208, 128 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 160, 208, 128 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 80, 104, 128) 0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 80, 104, 256) 295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 80, 104, 256) 590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 80, 104, 256) 590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 40, 52, 256)  0           block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 40, 52, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 40, 52, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 40, 52, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 20, 26, 512)  0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 20, 26, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 20, 26, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 20, 26, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)      (None, 10, 13, 512)  0           block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block6_conv1 (Conv2D)           (None, 10, 13, 4096) 102764544   block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6_dropout1 (Dropout)       (None, 10, 13, 4096) 0           block6_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block6_conv2 (Conv2D)           (None, 10, 13, 4096) 16781312    block6_dropout1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_dropout2 (Dropout)       (None, 10, 13, 4096) 0           block6_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block6_conv3 (Conv2D)           (None, 10, 13, 12)   49164       block6_dropout2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_deconv1 (Conv2DTranspose (None, 20, 26, 12)   2304        block6_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block7_conv1 (Conv2D)           (None, 20, 26, 12)   6156        block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7_Add (Add)                (None, 20, 26, 12)   0           block6_deconv1[0][0]             \n",
      "                                                                 block7_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 40, 52, 12)   2316        block7_Add[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block8_conv1 (Conv2D)           (None, 40, 52, 12)   3084        block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block8_Add (Add)                (None, 40, 52, 12)   0           conv2d_transpose_2[0][0]         \n",
      "                                                                 block8_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block8_Deconv (Conv2DTranspose) (None, 320, 416, 12) 36876       block8_Add[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "y_ (Activation)                 (None, 320, 416, 12) 0           block8_Deconv[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 134,360,444\n",
      "Trainable params: 119,645,756\n",
      "Non-trainable params: 14,714,688\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from models.fcn8 import model_fcn8\n",
    "\n",
    "model = model_fcn8(12, image_shape=(320, 416, 3), keep_prob=0.5)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from gen.datagen import balanced_generator_from_df\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "model_dir = '../../saved_models/fcn8/fcn8_v3/'\n",
    "\n",
    "\n",
    "train_gen = balanced_generator_from_df(train_df, BATCH_SIZE, (320, 416))\n",
    "valid_gen = balanced_generator_from_df(valid_df, BATCH_SIZE, (320, 416))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import euclidean_distance_loss\n",
    "from keras.utils.training_utils import multi_gpu_model\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "gpus = 2\n",
    "\n",
    "# opt = RMSprop(lr=1e-06)\n",
    "model_gpu = multi_gpu_model(model, gpus)\n",
    "model_gpu.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "75/75 [==============================] - 88s 1s/step - loss: 0.7549 - acc: 0.9511 - val_loss: 1.7548 - val_acc: 0.8854\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.75483, saving model to ../../saved_models/fcn8/fcn8_v3//model.hdf5\n",
      "Epoch 2/100\n",
      "75/75 [==============================] - 78s 1s/step - loss: 0.6514 - acc: 0.9574 - val_loss: 1.7256 - val_acc: 0.8855\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.75483 to 1.72558, saving model to ../../saved_models/fcn8/fcn8_v3//model.hdf5\n",
      "Epoch 3/100\n",
      "75/75 [==============================] - 79s 1s/step - loss: 0.6150 - acc: 0.9589 - val_loss: 1.6912 - val_acc: 0.8836\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.72558 to 1.69121, saving model to ../../saved_models/fcn8/fcn8_v3//model.hdf5\n",
      "Epoch 4/100\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.5833 - acc: 0.9579 - val_loss: 1.6953 - val_acc: 0.8783\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/100\n",
      "75/75 [==============================] - 79s 1s/step - loss: 0.5406 - acc: 0.9606 - val_loss: 1.7207 - val_acc: 0.8769\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 6/100\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.4932 - acc: 0.9625 - val_loss: 1.7030 - val_acc: 0.8719\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 7/100\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.4374 - acc: 0.9637 - val_loss: 1.6133 - val_acc: 0.8705\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.69121 to 1.61328, saving model to ../../saved_models/fcn8/fcn8_v3//model.hdf5\n",
      "Epoch 8/100\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.3783 - acc: 0.9643 - val_loss: 1.4870 - val_acc: 0.8647\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.61328 to 1.48702, saving model to ../../saved_models/fcn8/fcn8_v3//model.hdf5\n",
      "Epoch 9/100\n",
      "75/75 [==============================] - 79s 1s/step - loss: 0.3304 - acc: 0.9651 - val_loss: 1.4192 - val_acc: 0.8606\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.48702 to 1.41920, saving model to ../../saved_models/fcn8/fcn8_v3//model.hdf5\n",
      "Epoch 10/100\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.3003 - acc: 0.9658 - val_loss: 1.3836 - val_acc: 0.8608\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.41920 to 1.38363, saving model to ../../saved_models/fcn8/fcn8_v3//model.hdf5\n",
      "Epoch 11/100\n",
      "75/75 [==============================] - 79s 1s/step - loss: 0.2726 - acc: 0.9668 - val_loss: 1.3597 - val_acc: 0.8563\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.38363 to 1.35969, saving model to ../../saved_models/fcn8/fcn8_v3//model.hdf5\n",
      "Epoch 12/100\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.2453 - acc: 0.9670 - val_loss: 1.3142 - val_acc: 0.8534\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.35969 to 1.31421, saving model to ../../saved_models/fcn8/fcn8_v3//model.hdf5\n",
      "Epoch 13/100\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.2215 - acc: 0.9676 - val_loss: 1.2854 - val_acc: 0.8547\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.31421 to 1.28537, saving model to ../../saved_models/fcn8/fcn8_v3//model.hdf5\n",
      "Epoch 14/100\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.1967 - acc: 0.9684 - val_loss: 1.2596 - val_acc: 0.8535\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.28537 to 1.25961, saving model to ../../saved_models/fcn8/fcn8_v3//model.hdf5\n",
      "Epoch 15/100\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.1818 - acc: 0.9688 - val_loss: 1.2169 - val_acc: 0.8501\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.25961 to 1.21693, saving model to ../../saved_models/fcn8/fcn8_v3//model.hdf5\n",
      "Epoch 16/100\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.1686 - acc: 0.9691 - val_loss: 1.1466 - val_acc: 0.8522\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.21693 to 1.14659, saving model to ../../saved_models/fcn8/fcn8_v3//model.hdf5\n",
      "Epoch 17/100\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.1590 - acc: 0.9694 - val_loss: 1.0930 - val_acc: 0.8520\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.14659 to 1.09296, saving model to ../../saved_models/fcn8/fcn8_v3//model.hdf5\n",
      "Epoch 18/100\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.1508 - acc: 0.9697 - val_loss: 1.0547 - val_acc: 0.8518\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.09296 to 1.05465, saving model to ../../saved_models/fcn8/fcn8_v3//model.hdf5\n",
      "Epoch 19/100\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.1452 - acc: 0.9699 - val_loss: 1.0270 - val_acc: 0.8500\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.05465 to 1.02704, saving model to ../../saved_models/fcn8/fcn8_v3//model.hdf5\n",
      "Epoch 20/100\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.1387 - acc: 0.9703 - val_loss: 0.9577 - val_acc: 0.8557\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.02704 to 0.95773, saving model to ../../saved_models/fcn8/fcn8_v3//model.hdf5\n",
      "Epoch 21/100\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.1331 - acc: 0.9702 - val_loss: 0.9561 - val_acc: 0.8536\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.95773 to 0.95609, saving model to ../../saved_models/fcn8/fcn8_v3//model.hdf5\n",
      "Epoch 22/100\n",
      "75/75 [==============================] - 79s 1s/step - loss: 0.1278 - acc: 0.9707 - val_loss: 0.9040 - val_acc: 0.8557\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.95609 to 0.90399, saving model to ../../saved_models/fcn8/fcn8_v3//model.hdf5\n",
      "Epoch 23/100\n",
      "75/75 [==============================] - 79s 1s/step - loss: 0.1245 - acc: 0.9710 - val_loss: 0.9010 - val_acc: 0.8545\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.90399 to 0.90105, saving model to ../../saved_models/fcn8/fcn8_v3//model.hdf5\n",
      "Epoch 24/100\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.1235 - acc: 0.9707 - val_loss: 0.9243 - val_acc: 0.8546\n",
      "\n",
      "Epoch 00024: val_loss did not improve\n",
      "Epoch 25/100\n",
      "75/75 [==============================] - 79s 1s/step - loss: 0.1198 - acc: 0.9714 - val_loss: 0.8736 - val_acc: 0.8568\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.90105 to 0.87360, saving model to ../../saved_models/fcn8/fcn8_v3//model.hdf5\n",
      "Epoch 26/100\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.1181 - acc: 0.9713 - val_loss: 0.8691 - val_acc: 0.8550\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.87360 to 0.86912, saving model to ../../saved_models/fcn8/fcn8_v3//model.hdf5\n",
      "Epoch 27/100\n",
      "75/75 [==============================] - 79s 1s/step - loss: 0.1153 - acc: 0.9715 - val_loss: 0.8622 - val_acc: 0.8573\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.86912 to 0.86216, saving model to ../../saved_models/fcn8/fcn8_v3//model.hdf5\n",
      "Epoch 28/100\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.1095 - acc: 0.9720 - val_loss: 0.8517 - val_acc: 0.8556\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.86216 to 0.85169, saving model to ../../saved_models/fcn8/fcn8_v3//model.hdf5\n",
      "Epoch 29/100\n",
      "75/75 [==============================] - 82s 1s/step - loss: 0.1078 - acc: 0.9719 - val_loss: 0.8369 - val_acc: 0.8585\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.85169 to 0.83695, saving model to ../../saved_models/fcn8/fcn8_v3//model.hdf5\n",
      "Epoch 30/100\n",
      "75/75 [==============================] - 82s 1s/step - loss: 0.1035 - acc: 0.9727 - val_loss: 0.8291 - val_acc: 0.8598\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.83695 to 0.82907, saving model to ../../saved_models/fcn8/fcn8_v3//model.hdf5\n",
      "Epoch 31/100\n",
      "75/75 [==============================] - 79s 1s/step - loss: 0.1038 - acc: 0.9724 - val_loss: 0.8213 - val_acc: 0.8603\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.82907 to 0.82132, saving model to ../../saved_models/fcn8/fcn8_v3//model.hdf5\n",
      "Epoch 32/100\n",
      "75/75 [==============================] - 79s 1s/step - loss: 0.1025 - acc: 0.9727 - val_loss: 0.8367 - val_acc: 0.8565\n",
      "\n",
      "Epoch 00032: val_loss did not improve\n",
      "Epoch 33/100\n",
      "75/75 [==============================] - 78s 1s/step - loss: 0.1012 - acc: 0.9728 - val_loss: 0.8039 - val_acc: 0.8627\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.82132 to 0.80385, saving model to ../../saved_models/fcn8/fcn8_v3//model.hdf5\n",
      "Epoch 34/100\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.1014 - acc: 0.9725 - val_loss: 0.8187 - val_acc: 0.8624\n",
      "\n",
      "Epoch 00034: val_loss did not improve\n",
      "Epoch 35/100\n",
      "75/75 [==============================] - 79s 1s/step - loss: 0.0997 - acc: 0.9730 - val_loss: 0.8087 - val_acc: 0.8614\n",
      "\n",
      "Epoch 00035: val_loss did not improve\n",
      "Epoch 36/100\n",
      "75/75 [==============================] - 79s 1s/step - loss: 0.0979 - acc: 0.9734 - val_loss: 0.8202 - val_acc: 0.8599\n",
      "\n",
      "Epoch 00036: val_loss did not improve\n",
      "Epoch 37/100\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.1005 - acc: 0.9728 - val_loss: 0.8258 - val_acc: 0.8594\n",
      "\n",
      "Epoch 00037: val_loss did not improve\n",
      "Epoch 38/100\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.0970 - acc: 0.9733 - val_loss: 0.7999 - val_acc: 0.8646\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.80385 to 0.79991, saving model to ../../saved_models/fcn8/fcn8_v3//model.hdf5\n",
      "Epoch 39/100\n",
      "75/75 [==============================] - 78s 1s/step - loss: 0.0970 - acc: 0.9731 - val_loss: 0.8235 - val_acc: 0.8603\n",
      "\n",
      "Epoch 00039: val_loss did not improve\n",
      "Epoch 40/100\n",
      "75/75 [==============================] - 80s 1s/step - loss: 0.0949 - acc: 0.9735 - val_loss: 0.7879 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.79991 to 0.78786, saving model to ../../saved_models/fcn8/fcn8_v3//model.hdf5\n",
      "Epoch 41/100\n",
      "75/75 [==============================] - 79s 1s/step - loss: 0.0941 - acc: 0.9737 - val_loss: 0.8086 - val_acc: 0.8637\n",
      "\n",
      "Epoch 00041: val_loss did not improve\n",
      "Epoch 42/100\n",
      "75/75 [==============================] - 78s 1s/step - loss: 0.0923 - acc: 0.9738 - val_loss: 0.8272 - val_acc: 0.8605\n",
      "\n",
      "Epoch 00042: val_loss did not improve\n",
      "Epoch 43/100\n",
      "13/75 [====>.........................] - ETA: 59s - loss: 0.0955 - acc: 0.9727 "
     ]
    }
   ],
   "source": [
    "from train import train_nn\n",
    "\n",
    "m = train_df.shape[0]\n",
    "history = train_nn(model_gpu, \n",
    "                   train_gen, \n",
    "                   valid_gen, \n",
    "                   training_size=m, \n",
    "                   batch_size=BATCH_SIZE,\n",
    "                   validation_size=valid_df.shape[0],\n",
    "                   output_path=model_dir, \n",
    "                   epochs=100,\n",
    "                  gpus = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-38b499f7410e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# # summarize history for accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "# # summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../../saved_models/fcn8/fcn8_v3/model_saved.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#valid_gen = train_and_lab_gen_func(valid_df, image_size=(600, 800), target_size=(480, 480), batch_size = BATCH_SIZE * gpus)\n",
    "#test_gen = train_and_lab_gen_func(test_df, image_size=(600, 800),  target_size=(480, 480),  batch_size = BATCH_SIZE * gpus)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ai]",
   "language": "python",
   "name": "conda-env-ai-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
