{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage.io import imread\n",
    "\n",
    "from gen.load_data import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                image                   id  \\\n",
      "586   ../data/Train/CameraRGB/episode_0001_000017.png  episode_0001_000017   \n",
      "986   ../data/Train/CameraRGB/episode_0000_000258.png  episode_0000_000258   \n",
      "1210  ../data/Train/CameraRGB/episode_0003_000067.png  episode_0003_000067   \n",
      "2240                  ../data/Train/CameraRGB/617.png                  617   \n",
      "594                   ../data/Train/CameraRGB/100.png                  100   \n",
      "\n",
      "                                                label  \n",
      "586   ../data/Train/CameraSeg/episode_0001_000017.png  \n",
      "986   ../data/Train/CameraSeg/episode_0000_000258.png  \n",
      "1210  ../data/Train/CameraSeg/episode_0003_000067.png  \n",
      "2240                  ../data/Train/CameraSeg/617.png  \n",
      "594                   ../data/Train/CameraSeg/100.png  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "train_df, valid_df, test_df = load_data('../data')\n",
    "\n",
    "train_df = shuffle(train_df)\n",
    "valid_df = shuffle(valid_df)\n",
    "\n",
    "print(train_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        (None, 360, 480, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 360, 480, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 360, 480, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 180, 240, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 180, 240, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 180, 240, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 90, 120, 128)      0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 90, 120, 256)      295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 90, 120, 256)      590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 90, 120, 256)      590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 45, 60, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 45, 60, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 45, 60, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 45, 60, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 22, 30, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 22, 30, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 22, 30, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 22, 30, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 11, 15, 512)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_35 (ZeroPaddi (None, 13, 17, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 13, 17, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 13, 17, 512)       2048      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_25 (UpSampling (None, 26, 34, 512)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_36 (ZeroPaddi (None, 28, 36, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 28, 36, 256)       1179904   \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 28, 36, 256)       1024      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_26 (UpSampling (None, 56, 72, 256)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_37 (ZeroPaddi (None, 58, 74, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 58, 74, 128)       295040    \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 58, 74, 128)       512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_27 (UpSampling (None, 116, 148, 128)     0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_38 (ZeroPaddi (None, 118, 150, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 118, 150, 64)      73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 118, 150, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 118, 150, 3)       1731      \n",
      "_________________________________________________________________\n",
      "y_ (Activation)              (None, 118, 150, 3)       0         \n",
      "=================================================================\n",
      "Total params: 18,628,803\n",
      "Trainable params: 3,912,195\n",
      "Non-trainable params: 14,716,608\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from models.segnet import model_segnetVGG16\n",
    "\n",
    "model = model_segnetVGG16(3, image_shape=(360, 480, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from gen.generators import train_and_lab_gen_func\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "train_gen = train_and_lab_gen_func(train_df, image_size=(600, 800), target_size=(480, 480), batch_size = BATCH_SIZE)\n",
    "valid_gen = train_and_lab_gen_func(valid_df, image_size=(600, 800), target_size=(480, 480), batch_size = BATCH_SIZE)\n",
    "# test_gen = train_and_lab_gen_func(test_df, image_size=(600, 800),  target_size=(480, 480),  batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/faisal/anaconda3/envs/ai/lib/python3.6/site-packages/keras/engine/training.py:2095: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Ignore next message from keras, values are replaced anyways\n",
      "## Ignore next message from keras, values are replaced anyways\n",
      "Found 0 images belonging to 0 classes.\n",
      "## Ignore next message from keras, values are replaced anyways\n",
      "Found 0 images belonging to 0 classes.\n",
      "Found 0 images belonging to 0 classes.\n",
      "## Ignore next message from keras, values are replaced anyways\n",
      "Found 0 images belonging to 0 classes.\n",
      "Reinserting dataframe: 500 images\n",
      "## Ignore next message from keras, values are replaced anyways\n",
      "Found 0 images belonging to 0 classes.\n",
      "## Ignore next message from keras, values are replaced anyways\n",
      "Reinserting dataframe: 500 images\n",
      "## Ignore next message from keras, values are replaced anyways\n",
      "Found 0 images belonging to 0 classes.\n",
      "## Ignore next message from keras, values are replaced anyways\n",
      "Found 0 images belonging to 0 classes.\n",
      "Reinserting dataframe: 500 images\n",
      "## Ignore next message from keras, values are replaced anyways\n",
      "Found 0 images belonging to 0 classes.\n",
      "## Ignore next message from keras, values are replaced anyways\n",
      "Found 0 images belonging to 0 classes.\n",
      "Reinserting dataframe: 500 images\n",
      "## Ignore next message from keras, values are replaced anyways\n",
      "Found 0 images belonging to 0 classes.\n",
      "## Ignore next message from keras, values are replaced anyways\n",
      "Found 0 images belonging to 0 classes.\n",
      "Found 0 images belonging to 0 classes.\n",
      "Reinserting dataframe: 500 images\n",
      "Reinserting dataframe: 500 images\n",
      "Reinserting dataframe: 2500 images\n",
      "## Ignore next message from keras, values are replaced anyways\n",
      "Found 0 images belonging to 0 classes.\n",
      "Reinserting dataframe: 500 images\n",
      "Reinserting dataframe: 2500 images\n",
      "## Ignore next message from keras, values are replaced anyways\n",
      "Found 0 images belonging to 0 classes.\n",
      "Reinserting dataframe: 500 images\n",
      "Reinserting dataframe: 2500 images\n",
      "## Ignore next message from keras, values are replaced anyways\n",
      "Reinserting dataframe: 2500 images\n",
      "## Ignore next message from keras, values are replaced anyways\n",
      "Found 0 images belonging to 0 classes.\n",
      "Found 0 images belonging to 0 classes.\n",
      "Reinserting dataframe: 2500 images\n",
      "Epoch 1/100\n",
      "Reinserting dataframe: 2500 images\n",
      "Reinserting dataframe: 2500 images\n",
      "Reinserting dataframe: 2500 images\n",
      "78/78 [==============================] - 115s 1s/step - loss: 0.0204 - acc: 0.9954 - val_loss: 0.0659 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.06593, saving model to ../saved_models/fcn8_extended_v2/model.hdf5\n",
      "Epoch 2/100\n",
      "78/78 [==============================] - 106s 1s/step - loss: 0.0194 - acc: 0.9954 - val_loss: 0.0677 - val_acc: 0.9849\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/100\n",
      "78/78 [==============================] - 104s 1s/step - loss: 0.0187 - acc: 0.9954 - val_loss: 0.0604 - val_acc: 0.9853\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.06593 to 0.06044, saving model to ../saved_models/fcn8_extended_v2/model.hdf5\n",
      "Epoch 4/100\n",
      "78/78 [==============================] - 104s 1s/step - loss: 0.0170 - acc: 0.9954 - val_loss: 0.0550 - val_acc: 0.9857\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.06044 to 0.05504, saving model to ../saved_models/fcn8_extended_v2/model.hdf5\n",
      "Epoch 5/100\n",
      "78/78 [==============================] - 105s 1s/step - loss: 0.0159 - acc: 0.9955 - val_loss: 0.0589 - val_acc: 0.9843\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 6/100\n",
      "78/78 [==============================] - 105s 1s/step - loss: 0.0156 - acc: 0.9954 - val_loss: 0.0485 - val_acc: 0.9859\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.05504 to 0.04847, saving model to ../saved_models/fcn8_extended_v2/model.hdf5\n",
      "Epoch 7/100\n",
      "78/78 [==============================] - 106s 1s/step - loss: 0.0141 - acc: 0.9956 - val_loss: 0.0579 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 8/100\n",
      "78/78 [==============================] - 101s 1s/step - loss: 0.0141 - acc: 0.9954 - val_loss: 0.0458 - val_acc: 0.9865\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.04847 to 0.04584, saving model to ../saved_models/fcn8_extended_v2/model.hdf5\n",
      "Epoch 9/100\n",
      "78/78 [==============================] - 99s 1s/step - loss: 0.0131 - acc: 0.9955 - val_loss: 0.0517 - val_acc: 0.9848\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "Epoch 10/100\n",
      "78/78 [==============================] - 105s 1s/step - loss: 0.0126 - acc: 0.9956 - val_loss: 0.0503 - val_acc: 0.9855\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "Epoch 11/100\n",
      "78/78 [==============================] - 103s 1s/step - loss: 0.0126 - acc: 0.9956 - val_loss: 0.0422 - val_acc: 0.9869\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.04584 to 0.04218, saving model to ../saved_models/fcn8_extended_v2/model.hdf5\n",
      "Epoch 12/100\n",
      "78/78 [==============================] - 103s 1s/step - loss: 0.0125 - acc: 0.9955 - val_loss: 0.0456 - val_acc: 0.9863\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      "Epoch 13/100\n",
      "78/78 [==============================] - 105s 1s/step - loss: 0.0122 - acc: 0.9956 - val_loss: 0.0457 - val_acc: 0.9859\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      "Epoch 14/100\n",
      "78/78 [==============================] - 103s 1s/step - loss: 0.0118 - acc: 0.9957 - val_loss: 0.0493 - val_acc: 0.9853\n",
      "\n",
      "Epoch 00014: val_loss did not improve\n",
      "Epoch 15/100\n",
      "78/78 [==============================] - 107s 1s/step - loss: 0.0114 - acc: 0.9958 - val_loss: 0.0431 - val_acc: 0.9868\n",
      "\n",
      "Epoch 00015: val_loss did not improve\n",
      "Epoch 16/100\n",
      "78/78 [==============================] - 104s 1s/step - loss: 0.0118 - acc: 0.9956 - val_loss: 0.0501 - val_acc: 0.9848\n",
      "\n",
      "Epoch 00016: val_loss did not improve\n",
      "Epoch 17/100\n",
      "78/78 [==============================] - 102s 1s/step - loss: 0.0118 - acc: 0.9956 - val_loss: 0.0446 - val_acc: 0.9865\n",
      "\n",
      "Epoch 00017: val_loss did not improve\n",
      "Epoch 18/100\n",
      "78/78 [==============================] - 104s 1s/step - loss: 0.0115 - acc: 0.9957 - val_loss: 0.0452 - val_acc: 0.9861\n",
      "\n",
      "Epoch 00018: val_loss did not improve\n",
      "Epoch 19/100\n",
      "78/78 [==============================] - 104s 1s/step - loss: 0.0117 - acc: 0.9956 - val_loss: 0.0455 - val_acc: 0.9862\n",
      "\n",
      "Epoch 00019: val_loss did not improve\n",
      "Epoch 20/100\n",
      "78/78 [==============================] - 105s 1s/step - loss: 0.0113 - acc: 0.9958 - val_loss: 0.0457 - val_acc: 0.9862\n",
      "\n",
      "Epoch 00020: val_loss did not improve\n",
      "Epoch 21/100\n",
      "78/78 [==============================] - 105s 1s/step - loss: 0.0114 - acc: 0.9957 - val_loss: 0.0476 - val_acc: 0.9857\n",
      "\n",
      "Epoch 00021: val_loss did not improve\n"
     ]
    }
   ],
   "source": [
    "from train import train_nn\n",
    "\n",
    "m = train_df.shape[0]\n",
    "history = train_nn(model, \n",
    "                   train_gen, \n",
    "                   valid_gen, \n",
    "                   training_size=m, \n",
    "                   batch_size=BATCH_SIZE,\n",
    "                   validation_size=valid_df.shape[0],\n",
    "                   output_path='../saved_models/fcn8_extended_v2', \n",
    "                   epochs=100,\n",
    "                  gpus = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'History' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-38b499f7410e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# # summarize history for accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'History' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# # summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../saved_models/fcn8_extended_v2/model_saved.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#valid_gen = train_and_lab_gen_func(valid_df, image_size=(600, 800), target_size=(480, 480), batch_size = BATCH_SIZE * gpus)\n",
    "#test_gen = train_and_lab_gen_func(test_df, image_size=(600, 800),  target_size=(480, 480),  batch_size = BATCH_SIZE * gpus)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ai]",
   "language": "python",
   "name": "conda-env-ai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
