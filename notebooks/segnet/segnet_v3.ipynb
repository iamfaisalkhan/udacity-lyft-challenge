{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('../../')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage.io import imread\n",
    "\n",
    "from gen.load_data import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               image                   id  \\\n",
      "0  ../../data/Train/CameraRGB/episode_0002_000287...  episode_0002_000287   \n",
      "1  ../../data/Train/CameraRGB/episode_0008_000112...  episode_0008_000112   \n",
      "2                 ../../data/Train/CameraRGB/804.png                  804   \n",
      "3  ../../data/Train/CameraRGB/episode_0008_000286...  episode_0008_000286   \n",
      "4  ../../data/Train/CameraRGB/episode_0003_000261...  episode_0003_000261   \n",
      "\n",
      "                                               label  \n",
      "0  ../../data/Train/CameraSeg/episode_0002_000287...  \n",
      "1  ../../data/Train/CameraSeg/episode_0008_000112...  \n",
      "2                 ../../data/Train/CameraSeg/804.png  \n",
      "3  ../../data/Train/CameraSeg/episode_0008_000286...  \n",
      "4  ../../data/Train/CameraSeg/episode_0003_000261...  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "train_df, valid_df, test_df = load_data('../../data')\n",
    "\n",
    "\n",
    "print(train_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/faisal/anaconda3/envs/ai/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from models.segnet import model_segnetVGG16\n",
    "\n",
    "model = model_segnetVGG16(3, image_shape=(320, 416, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from gen.datagen import oversample_generator_from_df, balanced_generator_from_df\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "model_dir = '../../saved_models/segnet/segnet_v3/'\n",
    "\n",
    "if not os.path.exists(model_dir):\n",
    "    os.mkdir(model_dir)\n",
    "\n",
    "train_gen = oversample_generator_from_df(train_df, BATCH_SIZE, (320, 416), samples=2000)\n",
    "valid_gen = balanced_generator_from_df(valid_df, BATCH_SIZE, (320, 416))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy', 'mse'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/faisal/anaconda3/envs/ai/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "Epoch 1/500\n",
      "125/125 [==============================] - 142s 1s/step - loss: 0.6086 - acc: 0.8448 - mean_squared_error: 0.1076 - val_loss: 0.4471 - val_acc: 0.9298 - val_mean_squared_error: 0.0701\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.44714, saving model to ../../saved_models/segnet/segnet_v3//model.hdf5\n",
      "Epoch 2/500\n",
      "125/125 [==============================] - 82s 657ms/step - loss: 0.3976 - acc: 0.9312 - mean_squared_error: 0.0600 - val_loss: 0.8672 - val_acc: 0.7693 - val_mean_squared_error: 0.1347\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/500\n",
      "125/125 [==============================] - 82s 659ms/step - loss: 0.2970 - acc: 0.9566 - mean_squared_error: 0.0395 - val_loss: 0.3007 - val_acc: 0.9608 - val_mean_squared_error: 0.0377\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.44714 to 0.30066, saving model to ../../saved_models/segnet/segnet_v3//model.hdf5\n",
      "Epoch 4/500\n",
      "125/125 [==============================] - 82s 657ms/step - loss: 0.2425 - acc: 0.9636 - mean_squared_error: 0.0300 - val_loss: 0.2314 - val_acc: 0.9719 - val_mean_squared_error: 0.0257\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.30066 to 0.23138, saving model to ../../saved_models/segnet/segnet_v3//model.hdf5\n",
      "Epoch 5/500\n",
      "125/125 [==============================] - 84s 674ms/step - loss: 0.2003 - acc: 0.9698 - mean_squared_error: 0.0232 - val_loss: 0.1931 - val_acc: 0.9714 - val_mean_squared_error: 0.0213\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.23138 to 0.19306, saving model to ../../saved_models/segnet/segnet_v3//model.hdf5\n",
      "Epoch 6/500\n",
      "125/125 [==============================] - 82s 656ms/step - loss: 0.1690 - acc: 0.9740 - mean_squared_error: 0.0187 - val_loss: 0.1832 - val_acc: 0.9720 - val_mean_squared_error: 0.0203\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.19306 to 0.18316, saving model to ../../saved_models/segnet/segnet_v3//model.hdf5\n",
      "Epoch 7/500\n",
      "125/125 [==============================] - 82s 657ms/step - loss: 0.1527 - acc: 0.9734 - mean_squared_error: 0.0172 - val_loss: 0.1420 - val_acc: 0.9769 - val_mean_squared_error: 0.0148\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.18316 to 0.14204, saving model to ../../saved_models/segnet/segnet_v3//model.hdf5\n",
      "Epoch 8/500\n",
      "125/125 [==============================] - 83s 661ms/step - loss: 0.1306 - acc: 0.9766 - mean_squared_error: 0.0144 - val_loss: 0.1176 - val_acc: 0.9827 - val_mean_squared_error: 0.0112\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.14204 to 0.11764, saving model to ../../saved_models/segnet/segnet_v3//model.hdf5\n",
      "Epoch 9/500\n",
      "125/125 [==============================] - 84s 675ms/step - loss: 0.1420 - acc: 0.9675 - mean_squared_error: 0.0179 - val_loss: 0.1338 - val_acc: 0.9745 - val_mean_squared_error: 0.0152\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "Epoch 10/500\n",
      "125/125 [==============================] - 85s 678ms/step - loss: 0.1076 - acc: 0.9778 - mean_squared_error: 0.0123 - val_loss: 0.1024 - val_acc: 0.9852 - val_mean_squared_error: 0.0094\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.11764 to 0.10239, saving model to ../../saved_models/segnet/segnet_v3//model.hdf5\n",
      "Epoch 11/500\n",
      "125/125 [==============================] - 85s 677ms/step - loss: 0.0968 - acc: 0.9792 - mean_squared_error: 0.0111 - val_loss: 0.0940 - val_acc: 0.9857 - val_mean_squared_error: 0.0088\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.10239 to 0.09399, saving model to ../../saved_models/segnet/segnet_v3//model.hdf5\n",
      "Epoch 12/500\n",
      "125/125 [==============================] - 85s 677ms/step - loss: 0.0907 - acc: 0.9792 - mean_squared_error: 0.0108 - val_loss: 0.0828 - val_acc: 0.9868 - val_mean_squared_error: 0.0077\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.09399 to 0.08277, saving model to ../../saved_models/segnet/segnet_v3//model.hdf5\n",
      "Epoch 13/500\n",
      "125/125 [==============================] - 85s 678ms/step - loss: 0.0809 - acc: 0.9808 - mean_squared_error: 0.0097 - val_loss: 0.0740 - val_acc: 0.9874 - val_mean_squared_error: 0.0072\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.08277 to 0.07399, saving model to ../../saved_models/segnet/segnet_v3//model.hdf5\n",
      "Epoch 14/500\n",
      "125/125 [==============================] - 84s 675ms/step - loss: 0.0731 - acc: 0.9823 - mean_squared_error: 0.0088 - val_loss: 0.0733 - val_acc: 0.9855 - val_mean_squared_error: 0.0078\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.07399 to 0.07334, saving model to ../../saved_models/segnet/segnet_v3//model.hdf5\n",
      "Epoch 15/500\n",
      "125/125 [==============================] - 82s 659ms/step - loss: 0.0667 - acc: 0.9832 - mean_squared_error: 0.0082 - val_loss: 0.0667 - val_acc: 0.9865 - val_mean_squared_error: 0.0072\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.07334 to 0.06671, saving model to ../../saved_models/segnet/segnet_v3//model.hdf5\n",
      "Epoch 16/500\n",
      "125/125 [==============================] - 82s 657ms/step - loss: 0.0618 - acc: 0.9837 - mean_squared_error: 0.0078 - val_loss: 0.0590 - val_acc: 0.9881 - val_mean_squared_error: 0.0062\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.06671 to 0.05901, saving model to ../../saved_models/segnet/segnet_v3//model.hdf5\n",
      "Epoch 17/500\n",
      "125/125 [==============================] - 84s 674ms/step - loss: 0.0575 - acc: 0.9843 - mean_squared_error: 0.0075 - val_loss: 0.0831 - val_acc: 0.9776 - val_mean_squared_error: 0.0113\n",
      "\n",
      "Epoch 00017: val_loss did not improve\n",
      "Epoch 18/500\n",
      "125/125 [==============================] - 82s 657ms/step - loss: 0.0539 - acc: 0.9848 - mean_squared_error: 0.0072 - val_loss: 0.0599 - val_acc: 0.9858 - val_mean_squared_error: 0.0072\n",
      "\n",
      "Epoch 00018: val_loss did not improve\n",
      "Epoch 19/500\n",
      "125/125 [==============================] - 82s 656ms/step - loss: 0.0488 - acc: 0.9860 - mean_squared_error: 0.0066 - val_loss: 0.0487 - val_acc: 0.9895 - val_mean_squared_error: 0.0054\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.05901 to 0.04869, saving model to ../../saved_models/segnet/segnet_v3//model.hdf5\n",
      "Epoch 20/500\n",
      "125/125 [==============================] - 82s 655ms/step - loss: 0.0624 - acc: 0.9804 - mean_squared_error: 0.0094 - val_loss: 0.1497 - val_acc: 0.9577 - val_mean_squared_error: 0.0223\n",
      "\n",
      "Epoch 00020: val_loss did not improve\n",
      "Epoch 21/500\n",
      "125/125 [==============================] - 82s 657ms/step - loss: 0.0667 - acc: 0.9776 - mean_squared_error: 0.0106 - val_loss: 0.0545 - val_acc: 0.9861 - val_mean_squared_error: 0.0071\n",
      "\n",
      "Epoch 00021: val_loss did not improve\n",
      "Epoch 22/500\n",
      "125/125 [==============================] - 83s 662ms/step - loss: 0.0502 - acc: 0.9829 - mean_squared_error: 0.0077 - val_loss: 0.0484 - val_acc: 0.9874 - val_mean_squared_error: 0.0062\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.04869 to 0.04840, saving model to ../../saved_models/segnet/segnet_v3//model.hdf5\n",
      "Epoch 23/500\n",
      "125/125 [==============================] - 82s 656ms/step - loss: 0.0464 - acc: 0.9840 - mean_squared_error: 0.0072 - val_loss: 0.0456 - val_acc: 0.9879 - val_mean_squared_error: 0.0060\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.04840 to 0.04565, saving model to ../../saved_models/segnet/segnet_v3//model.hdf5\n",
      "Epoch 24/500\n",
      "125/125 [==============================] - 85s 677ms/step - loss: 0.0425 - acc: 0.9848 - mean_squared_error: 0.0067 - val_loss: 0.0410 - val_acc: 0.9897 - val_mean_squared_error: 0.0052\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.04565 to 0.04097, saving model to ../../saved_models/segnet/segnet_v3//model.hdf5\n",
      "Epoch 25/500\n",
      "125/125 [==============================] - 84s 675ms/step - loss: 0.0388 - acc: 0.9859 - mean_squared_error: 0.0062 - val_loss: 0.0460 - val_acc: 0.9872 - val_mean_squared_error: 0.0064\n",
      "\n",
      "Epoch 00025: val_loss did not improve\n",
      "Epoch 26/500\n",
      "125/125 [==============================] - 85s 677ms/step - loss: 0.0365 - acc: 0.9864 - mean_squared_error: 0.0059 - val_loss: 0.0399 - val_acc: 0.9890 - val_mean_squared_error: 0.0054\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.04097 to 0.03986, saving model to ../../saved_models/segnet/segnet_v3//model.hdf5\n",
      "Epoch 27/500\n",
      "125/125 [==============================] - 84s 676ms/step - loss: 0.0345 - acc: 0.9870 - mean_squared_error: 0.0057 - val_loss: 0.0364 - val_acc: 0.9907 - val_mean_squared_error: 0.0047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00027: val_loss improved from 0.03986 to 0.03641, saving model to ../../saved_models/segnet/segnet_v3//model.hdf5\n",
      "Epoch 28/500\n",
      "125/125 [==============================] - 82s 653ms/step - loss: 0.0329 - acc: 0.9871 - mean_squared_error: 0.0057 - val_loss: 0.0351 - val_acc: 0.9904 - val_mean_squared_error: 0.0048\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.03641 to 0.03509, saving model to ../../saved_models/segnet/segnet_v3//model.hdf5\n",
      "Epoch 30/500\n",
      "125/125 [==============================] - 82s 658ms/step - loss: 0.0310 - acc: 0.9876 - mean_squared_error: 0.0055 - val_loss: 0.0366 - val_acc: 0.9899 - val_mean_squared_error: 0.0051\n",
      "\n",
      "Epoch 00030: val_loss did not improve\n",
      "Epoch 31/500\n",
      "125/125 [==============================] - 82s 658ms/step - loss: 0.0293 - acc: 0.9882 - mean_squared_error: 0.0053 - val_loss: 0.0342 - val_acc: 0.9904 - val_mean_squared_error: 0.0048\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.03509 to 0.03418, saving model to ../../saved_models/segnet/segnet_v3//model.hdf5\n",
      "Epoch 32/500\n",
      "125/125 [==============================] - 82s 657ms/step - loss: 0.0366 - acc: 0.9850 - mean_squared_error: 0.0067 - val_loss: 0.0406 - val_acc: 0.9882 - val_mean_squared_error: 0.0060\n",
      "\n",
      "Epoch 00032: val_loss did not improve\n",
      "Epoch 33/500\n",
      "125/125 [==============================] - 84s 676ms/step - loss: 0.0320 - acc: 0.9862 - mean_squared_error: 0.0059 - val_loss: 0.0335 - val_acc: 0.9903 - val_mean_squared_error: 0.0049\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.03418 to 0.03350, saving model to ../../saved_models/segnet/segnet_v3//model.hdf5\n",
      "Epoch 34/500\n",
      "125/125 [==============================] - 84s 675ms/step - loss: 0.0280 - acc: 0.9880 - mean_squared_error: 0.0053 - val_loss: 0.0364 - val_acc: 0.9889 - val_mean_squared_error: 0.0055\n",
      "\n",
      "Epoch 00034: val_loss did not improve\n",
      "Epoch 35/500\n",
      "  3/125 [..............................] - ETA: 1:13 - loss: 0.0267 - acc: 0.9882 - mean_squared_error: 0.0052"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-7462a0402397>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m                    \u001b[0moutput_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                    \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                    gpus = 1)\n\u001b[0m",
      "\u001b[0;32m/data/udacity/lyft_challenge/train.py\u001b[0m in \u001b[0;36mtrain_nn\u001b[0;34m(model, train_gen, valid_gen, training_size, validation_size, output_path, batch_size, epochs, workers, verbose, lr, gpus)\u001b[0m\n\u001b[1;32m    125\u001b[0m                                 \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                                 \u001b[0;31m#use_multiprocessing=True,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m                                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m                                 )\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2242\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2243\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2244\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2246\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1888\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1890\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1891\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1892\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from train import train_nn\n",
    "\n",
    "m = train_df.shape[0]\n",
    "history = train_nn(model, \n",
    "                   train_gen, \n",
    "                   valid_gen, \n",
    "                   training_size=2000, \n",
    "                   batch_size=BATCH_SIZE,\n",
    "                   validation_size=valid_df.shape[0],\n",
    "                   output_path=model_dir, \n",
    "                   epochs=500,\n",
    "                   gpus = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('../../saved_models/segnet/segnet_v3//model.hdf5')\n",
    "model.save('../../saved_models/segnet/segnet_v3/model_saved.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ai]",
   "language": "python",
   "name": "conda-env-ai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
