{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('../../')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage.io import imread\n",
    "\n",
    "from gen.load_data import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               image                   id  \\\n",
      "0  ../../data/Train/CameraRGB/episode_0002_000287...  episode_0002_000287   \n",
      "1  ../../data/Train/CameraRGB/episode_0008_000112...  episode_0008_000112   \n",
      "2                 ../../data/Train/CameraRGB/804.png                  804   \n",
      "3  ../../data/Train/CameraRGB/episode_0008_000286...  episode_0008_000286   \n",
      "4  ../../data/Train/CameraRGB/episode_0014_000061...  episode_0014_000061   \n",
      "\n",
      "                                               label  \n",
      "0  ../../data/Train/CameraSeg/episode_0002_000287...  \n",
      "1  ../../data/Train/CameraSeg/episode_0008_000112...  \n",
      "2                 ../../data/Train/CameraSeg/804.png  \n",
      "3  ../../data/Train/CameraSeg/episode_0008_000286...  \n",
      "4  ../../data/Train/CameraSeg/episode_0014_000061...  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "train_df, valid_df, test_df = load_data('../../data')\n",
    "\n",
    "\n",
    "print(train_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 416, 544, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 416, 544, 64) 1792        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 416, 544, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 208, 272, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 208, 272, 128 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 208, 272, 128 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 104, 136, 128 0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 104, 136, 256 295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 104, 136, 256 590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 104, 136, 256 590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 52, 68, 256)  0           block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 52, 68, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 52, 68, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 52, 68, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 26, 34, 512)  0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 26, 34, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 26, 34, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 26, 34, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)      (None, 13, 17, 512)  0           block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 13, 17, 512)  2048        block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_11 (Conv2DTran (None, 26, 34, 512)  2359808     batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 26, 34, 1024) 0           conv2d_transpose_11[0][0]        \n",
      "                                                                 block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 26, 34, 512)  4719104     concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 26, 34, 256)  1179904     conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_12 (Conv2DTran (None, 52, 68, 256)  590080      conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 52, 68, 256)  1024        block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 52, 68, 512)  0           conv2d_transpose_12[0][0]        \n",
      "                                                                 batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 52, 68, 256)  1179904     concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 52, 68, 128)  295040      conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_13 (Conv2DTran (None, 104, 136, 128 147584      conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 104, 136, 128 512         block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 104, 136, 256 0           conv2d_transpose_13[0][0]        \n",
      "                                                                 batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 104, 136, 128 295040      concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 104, 136, 64) 73792       conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_14 (Conv2DTran (None, 208, 272, 64) 36928       conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 208, 272, 64) 256         block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 208, 272, 128 0           conv2d_transpose_14[0][0]        \n",
      "                                                                 batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 208, 272, 64) 73792       concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 208, 272, 32) 18464       conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_15 (Conv2DTran (None, 416, 544, 3)  867         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 416, 544, 3)  12          conv2d_transpose_15[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "y_ (Activation)                 (None, 416, 544, 3)  0           conv2d_27[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 25,688,847\n",
      "Trainable params: 10,972,239\n",
      "Non-trainable params: 14,716,608\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from models.unet import model_unetVGG16_v1\n",
    "\n",
    "\n",
    "model = model_unetVGG16_v1(3, image_shape=(416, 544, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from gen.datagen import oversample_generator_from_df, balanced_generator_from_df\n",
    "\n",
    "GPUS = 2\n",
    "BATCH_SIZE = 32 * GPUS\n",
    "model_dir = '../../saved_models/unet/unet_v7/'\n",
    "\n",
    "if not os.path.exists(model_dir):\n",
    "    os.mkdir(model_dir)\n",
    "\n",
    "from gen.generators import gen_func, preprocess_label, preprocess_multi_label\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "\n",
    "rgb_gen = ImageDataGenerator()\n",
    "lab_gen = ImageDataGenerator()\n",
    "\n",
    "train_gen = gen_func(train_df, rgb_gen, lab_gen, image_size=(600, 800), target_size=(416, 544), batch_size = BATCH_SIZE, perturb=True)\n",
    "valid_gen = gen_func(valid_df, rgb_gen, lab_gen, image_size=(600, 800), target_size=(416, 544), batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.training_utils import multi_gpu_model\n",
    "from train import weighted_categorical_crossentropy\n",
    "model_gpu = multi_gpu_model(model, GPUS)\n",
    "\n",
    "weights = np.array([10, 5, 1])\n",
    "model_gpu.compile(loss=weighted_categorical_crossentropy(weights),\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/faisal/anaconda3/envs/ai/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "## Ignore next message from keras, values are replaced anyways\n",
      "## Ignore next message from keras, values are replaced anyways\n",
      "Epoch 1/100\n",
      "Found 0 images belonging to 0 classes.\n",
      "Found 0 images belonging to 0 classes.\n",
      "Reinserting dataframe: 1683 images\n",
      "## Ignore next message from keras, values are replaced anyways\n",
      "Found 0 images belonging to 0 classes.\n",
      "Reinserting dataframe: 6159 images\n",
      "## Ignore next message from keras, values are replaced anyways\n",
      "Found 0 images belonging to 0 classes.\n",
      "Reinserting dataframe: 1683 images\n",
      "Reinserting dataframe: 6159 images\n",
      "48/48 [==============================] - 187s 4s/step - loss: 0.8905 - acc: 0.8365 - val_loss: 0.3741 - val_acc: 0.9658\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.37413, saving model to ../../saved_models/unet/unet_v7//model.hdf5\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 175s 4s/step - loss: 0.1438 - acc: 0.9765 - val_loss: 0.3218 - val_acc: 0.9813\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.37413 to 0.32175, saving model to ../../saved_models/unet/unet_v7//model.hdf5\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 174s 4s/step - loss: 0.0719 - acc: 0.9851 - val_loss: 0.2986 - val_acc: 0.9829\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.32175 to 0.29864, saving model to ../../saved_models/unet/unet_v7//model.hdf5\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 176s 4s/step - loss: 0.0545 - acc: 0.9875 - val_loss: 0.2739 - val_acc: 0.9840\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.29864 to 0.27387, saving model to ../../saved_models/unet/unet_v7//model.hdf5\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 173s 4s/step - loss: 0.0462 - acc: 0.9889 - val_loss: 0.3281 - val_acc: 0.9827\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 177s 4s/step - loss: 0.0413 - acc: 0.9898 - val_loss: 0.2391 - val_acc: 0.9846\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.27387 to 0.23909, saving model to ../../saved_models/unet/unet_v7//model.hdf5\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 174s 4s/step - loss: 0.0370 - acc: 0.9907 - val_loss: 0.2964 - val_acc: 0.9839\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 177s 4s/step - loss: 0.0356 - acc: 0.9910 - val_loss: 0.2117 - val_acc: 0.9859\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.23909 to 0.21171, saving model to ../../saved_models/unet/unet_v7//model.hdf5\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 174s 4s/step - loss: 0.0329 - acc: 0.9914 - val_loss: 0.2592 - val_acc: 0.9856\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 177s 4s/step - loss: 0.0309 - acc: 0.9918 - val_loss: 0.2077 - val_acc: 0.9866\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.21171 to 0.20773, saving model to ../../saved_models/unet/unet_v7//model.hdf5\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 173s 4s/step - loss: 0.0298 - acc: 0.9921 - val_loss: 0.2413 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 178s 4s/step - loss: 0.0304 - acc: 0.9921 - val_loss: 0.2012 - val_acc: 0.9872\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.20773 to 0.20124, saving model to ../../saved_models/unet/unet_v7//model.hdf5\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 173s 4s/step - loss: 0.0291 - acc: 0.9923 - val_loss: 0.2527 - val_acc: 0.9857\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 178s 4s/step - loss: 0.0272 - acc: 0.9927 - val_loss: 0.2188 - val_acc: 0.9870\n",
      "\n",
      "Epoch 00014: val_loss did not improve\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 173s 4s/step - loss: 9.0042 - acc: 0.5509 - val_loss: 12.9273 - val_acc: 0.2917\n",
      "\n",
      "Epoch 00015: val_loss did not improve\n",
      "Epoch 16/100\n",
      " 6/48 [==>...........................] - ETA: 1:32 - loss: 13.6587 - acc: 0.2861"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-8ed7f6ca5ec1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m                    \u001b[0moutput_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                    \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                    gpus = GPUS)\n\u001b[0m",
      "\u001b[0;32m/data/udacity/lyft_challenge/train.py\u001b[0m in \u001b[0;36mtrain_nn\u001b[0;34m(model, train_gen, valid_gen, training_size, validation_size, output_path, batch_size, epochs, workers, verbose, lr, gpus)\u001b[0m\n\u001b[1;32m    157\u001b[0m                                 \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                                 \u001b[0;31m# use_multiprocessing=True,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m                                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m                                 )\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2210\u001b[0m                 \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2211\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2212\u001b[0;31m                     \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai/lib/python3.6/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    771\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 773\u001b[0;31m                     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;31m# Make sure to rethrow the first exception in the queue, if any\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from train import train_nn\n",
    "\n",
    "m = train_df.shape[0]\n",
    "history = train_nn(model_gpu, \n",
    "                   train_gen, \n",
    "                   valid_gen, \n",
    "                   training_size=train_df.shape[0], \n",
    "                   batch_size=BATCH_SIZE,\n",
    "                   validation_size=valid_df.shape[0],\n",
    "                   output_path=model_dir, \n",
    "                   epochs=100,\n",
    "                   gpus = GPUS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gpu.load_weights('../../saved_models/unet/unet_v7/model.hdf5')\n",
    "# model.reset_states()\n",
    "model.save('../../saved_models/unet/unet_v7/model_saved.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ai]",
   "language": "python",
   "name": "conda-env-ai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
