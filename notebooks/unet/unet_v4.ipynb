{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('../../')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage.io import imread\n",
    "\n",
    "from gen.load_data import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               image                   id  \\\n",
      "0  ../../data/Train/CameraRGB/episode_0002_000287...  episode_0002_000287   \n",
      "1  ../../data/Train/CameraRGB/episode_0008_000112...  episode_0008_000112   \n",
      "2                 ../../data/Train/CameraRGB/804.png                  804   \n",
      "3  ../../data/Train/CameraRGB/episode_0008_000286...  episode_0008_000286   \n",
      "4  ../../data/Train/CameraRGB/episode_0003_000261...  episode_0003_000261   \n",
      "\n",
      "                                               label  \n",
      "0  ../../data/Train/CameraSeg/episode_0002_000287...  \n",
      "1  ../../data/Train/CameraSeg/episode_0008_000112...  \n",
      "2                 ../../data/Train/CameraSeg/804.png  \n",
      "3  ../../data/Train/CameraSeg/episode_0008_000286...  \n",
      "4  ../../data/Train/CameraSeg/episode_0003_000261...  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "train_df, valid_df, test_df = load_data('../../data')\n",
    "\n",
    "\n",
    "print(train_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 320, 416, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 320, 416, 64) 1792        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 320, 416, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 160, 208, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 160, 208, 128 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 160, 208, 128 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 80, 104, 128) 0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 80, 104, 256) 295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 80, 104, 256) 590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 80, 104, 256) 590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 40, 52, 256)  0           block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 40, 52, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 40, 52, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 40, 52, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 20, 26, 512)  0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 20, 26, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 20, 26, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 20, 26, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)      (None, 10, 13, 512)  0           block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTrans (None, 20, 26, 512)  2359808     block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 20, 26, 1024) 0           conv2d_transpose_6[0][0]         \n",
      "                                                                 block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 20, 26, 512)  4719104     concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 20, 26, 256)  1179904     conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTrans (None, 40, 52, 256)  590080      conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 40, 52, 256)  1024        block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 40, 52, 512)  0           conv2d_transpose_7[0][0]         \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 40, 52, 256)  1179904     concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 40, 52, 128)  295040      conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_8 (Conv2DTrans (None, 80, 104, 128) 147584      conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 80, 104, 128) 512         block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 80, 104, 256) 0           conv2d_transpose_8[0][0]         \n",
      "                                                                 batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 80, 104, 128) 295040      concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 80, 104, 64)  73792       conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_9 (Conv2DTrans (None, 160, 208, 64) 36928       conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 160, 208, 64) 256         block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 160, 208, 128 0           conv2d_transpose_9[0][0]         \n",
      "                                                                 batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 160, 208, 64) 73792       concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 160, 208, 3)  195         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_10 (Conv2DTran (None, 320, 416, 3)  84          conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "y_ (Activation)                 (None, 320, 416, 3)  0           conv2d_transpose_10[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 25,667,735\n",
      "Trainable params: 25,666,839\n",
      "Non-trainable params: 896\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from models.unet import model_unetVGG16\n",
    "\n",
    "model = model_unetVGG16(3, image_shape=(320, 416, 3), keep_prob=0.5)\n",
    "model.summary()\n",
    "model.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from gen.datagen import oversample_generator_from_df, balanced_generator_from_df\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "model_dir = '../../saved_models/unet/unet_v4/'\n",
    "\n",
    "if not os.path.exists(model_dir):\n",
    "    os.mkdir(model_dir)\n",
    "\n",
    "train_gen = oversample_generator_from_df(train_df, BATCH_SIZE, (320, 416))\n",
    "valid_gen = balanced_generator_from_df(valid_df, BATCH_SIZE, (320, 416))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import weighted_categorical_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "weights = np.array([10, 5, 1])\n",
    "\n",
    "opt = Adam(lr=1e-5)\n",
    "model.compile(loss=weighted_categorical_crossentropy(weights),\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "150/150 [==============================] - 112s 749ms/step - loss: 2.1027 - acc: 0.4901 - val_loss: 0.7357 - val_acc: 0.7822\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.73571, saving model to ../../saved_models/unet/unet_v4//model.hdf5\n",
      "Epoch 2/500\n",
      "150/150 [==============================] - 51s 339ms/step - loss: 1.0451 - acc: 0.8618 - val_loss: 0.5174 - val_acc: 0.9425\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.73571 to 0.51740, saving model to ../../saved_models/unet/unet_v4//model.hdf5\n",
      "Epoch 3/500\n",
      "150/150 [==============================] - 51s 341ms/step - loss: 0.8775 - acc: 0.9142 - val_loss: 0.4488 - val_acc: 0.9505\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.51740 to 0.44877, saving model to ../../saved_models/unet/unet_v4//model.hdf5\n",
      "Epoch 4/500\n",
      "150/150 [==============================] - 51s 339ms/step - loss: 0.7814 - acc: 0.9246 - val_loss: 0.4439 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.44877 to 0.44387, saving model to ../../saved_models/unet/unet_v4//model.hdf5\n",
      "Epoch 5/500\n",
      "150/150 [==============================] - 51s 341ms/step - loss: 0.7822 - acc: 0.9264 - val_loss: 0.4039 - val_acc: 0.9593\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.44387 to 0.40394, saving model to ../../saved_models/unet/unet_v4//model.hdf5\n",
      "Epoch 6/500\n",
      "150/150 [==============================] - 51s 340ms/step - loss: 0.7407 - acc: 0.9305 - val_loss: 0.3907 - val_acc: 0.9598\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.40394 to 0.39070, saving model to ../../saved_models/unet/unet_v4//model.hdf5\n",
      "Epoch 7/500\n",
      "150/150 [==============================] - 51s 340ms/step - loss: 0.6971 - acc: 0.9339 - val_loss: 0.3908 - val_acc: 0.9592\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 8/500\n",
      "150/150 [==============================] - 51s 341ms/step - loss: 0.6508 - acc: 0.9375 - val_loss: 0.4144 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "Epoch 9/500\n",
      "150/150 [==============================] - 51s 342ms/step - loss: 0.6598 - acc: 0.9378 - val_loss: 0.3842 - val_acc: 0.9618\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.39070 to 0.38421, saving model to ../../saved_models/unet/unet_v4//model.hdf5\n",
      "Epoch 10/500\n",
      "150/150 [==============================] - 51s 343ms/step - loss: 0.6453 - acc: 0.9400 - val_loss: 0.3851 - val_acc: 0.9675\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "Epoch 11/500\n",
      "150/150 [==============================] - 51s 340ms/step - loss: 0.5904 - acc: 0.9479 - val_loss: 0.3390 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.38421 to 0.33899, saving model to ../../saved_models/unet/unet_v4//model.hdf5\n",
      "Epoch 12/500\n",
      "150/150 [==============================] - 51s 341ms/step - loss: 0.5741 - acc: 0.9495 - val_loss: 0.3256 - val_acc: 0.9650\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.33899 to 0.32560, saving model to ../../saved_models/unet/unet_v4//model.hdf5\n",
      "Epoch 13/500\n",
      "150/150 [==============================] - 51s 342ms/step - loss: 0.5619 - acc: 0.9516 - val_loss: 0.3344 - val_acc: 0.9629\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      "Epoch 14/500\n",
      "150/150 [==============================] - 52s 344ms/step - loss: 0.5520 - acc: 0.9521 - val_loss: 0.3272 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00014: val_loss did not improve\n",
      "Epoch 15/500\n",
      "150/150 [==============================] - 51s 342ms/step - loss: 0.5484 - acc: 0.9517 - val_loss: 0.3343 - val_acc: 0.9703\n",
      "\n",
      "Epoch 00015: val_loss did not improve\n",
      "Epoch 16/500\n",
      "150/150 [==============================] - 50s 337ms/step - loss: 0.5019 - acc: 0.9542 - val_loss: 0.3633 - val_acc: 0.9708\n",
      "\n",
      "Epoch 00016: val_loss did not improve\n",
      "Epoch 17/500\n",
      "150/150 [==============================] - 52s 344ms/step - loss: 0.4874 - acc: 0.9548 - val_loss: 0.3296 - val_acc: 0.9728\n",
      "\n",
      "Epoch 00017: val_loss did not improve\n",
      "Epoch 18/500\n",
      "150/150 [==============================] - 52s 344ms/step - loss: 0.4391 - acc: 0.9571 - val_loss: 0.5521 - val_acc: 0.9701\n",
      "\n",
      "Epoch 00018: val_loss did not improve\n",
      "Epoch 19/500\n",
      "150/150 [==============================] - 52s 344ms/step - loss: 0.4688 - acc: 0.9551 - val_loss: 0.3020 - val_acc: 0.9733\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.32560 to 0.30199, saving model to ../../saved_models/unet/unet_v4//model.hdf5\n",
      "Epoch 20/500\n",
      "150/150 [==============================] - 51s 341ms/step - loss: 0.4098 - acc: 0.9583 - val_loss: 0.2921 - val_acc: 0.9733\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.30199 to 0.29207, saving model to ../../saved_models/unet/unet_v4//model.hdf5\n",
      "Epoch 21/500\n",
      "150/150 [==============================] - 51s 342ms/step - loss: 0.4045 - acc: 0.9582 - val_loss: 0.2812 - val_acc: 0.9744\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.29207 to 0.28122, saving model to ../../saved_models/unet/unet_v4//model.hdf5\n",
      "Epoch 22/500\n",
      "150/150 [==============================] - 52s 344ms/step - loss: 0.3892 - acc: 0.9589 - val_loss: 0.3407 - val_acc: 0.9749\n",
      "\n",
      "Epoch 00022: val_loss did not improve\n",
      "Epoch 23/500\n",
      "150/150 [==============================] - 51s 342ms/step - loss: 0.3731 - acc: 0.9606 - val_loss: 0.2948 - val_acc: 0.9740\n",
      "\n",
      "Epoch 00023: val_loss did not improve\n",
      "Epoch 24/500\n",
      "150/150 [==============================] - 52s 344ms/step - loss: 0.3433 - acc: 0.9624 - val_loss: 0.2821 - val_acc: 0.9782\n",
      "\n",
      "Epoch 00024: val_loss did not improve\n",
      "Epoch 25/500\n",
      "150/150 [==============================] - 52s 344ms/step - loss: 0.3225 - acc: 0.9648 - val_loss: 0.3053 - val_acc: 0.9808\n",
      "\n",
      "Epoch 00025: val_loss did not improve\n",
      "Epoch 26/500\n",
      "150/150 [==============================] - 52s 345ms/step - loss: 0.3382 - acc: 0.9650 - val_loss: 0.2645 - val_acc: 0.9793\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.28122 to 0.26452, saving model to ../../saved_models/unet/unet_v4//model.hdf5\n",
      "Epoch 27/500\n",
      "150/150 [==============================] - 52s 344ms/step - loss: 0.2928 - acc: 0.9658 - val_loss: 0.2924 - val_acc: 0.9800\n",
      "\n",
      "Epoch 00027: val_loss did not improve\n",
      "Epoch 28/500\n",
      "150/150 [==============================] - 51s 339ms/step - loss: 0.3447 - acc: 0.9637 - val_loss: 0.2302 - val_acc: 0.9726\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.26452 to 0.23022, saving model to ../../saved_models/unet/unet_v4//model.hdf5\n",
      "Epoch 29/500\n",
      "150/150 [==============================] - 51s 343ms/step - loss: 0.2759 - acc: 0.9724 - val_loss: 0.2315 - val_acc: 0.9841\n",
      "\n",
      "Epoch 00029: val_loss did not improve\n",
      "Epoch 30/500\n",
      "150/150 [==============================] - 52s 344ms/step - loss: 0.1768 - acc: 0.9793 - val_loss: 0.2444 - val_acc: 0.9845\n",
      "\n",
      "Epoch 00030: val_loss did not improve\n",
      "Epoch 31/500\n",
      "150/150 [==============================] - 52s 344ms/step - loss: 0.1566 - acc: 0.9803 - val_loss: 0.2195 - val_acc: 0.9845\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.23022 to 0.21946, saving model to ../../saved_models/unet/unet_v4//model.hdf5\n",
      "Epoch 32/500\n",
      "150/150 [==============================] - 52s 345ms/step - loss: 0.1772 - acc: 0.9800 - val_loss: 0.2407 - val_acc: 0.9849\n",
      "\n",
      "Epoch 00032: val_loss did not improve\n",
      "Epoch 33/500\n",
      "150/150 [==============================] - 52s 344ms/step - loss: 0.1586 - acc: 0.9807 - val_loss: 0.2344 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00033: val_loss did not improve\n",
      "Epoch 34/500\n",
      "150/150 [==============================] - 52s 344ms/step - loss: 0.1735 - acc: 0.9801 - val_loss: 0.2308 - val_acc: 0.9855\n",
      "\n",
      "Epoch 00034: val_loss did not improve\n",
      "Epoch 35/500\n",
      "150/150 [==============================] - 51s 342ms/step - loss: 0.1258 - acc: 0.9824 - val_loss: 0.2348 - val_acc: 0.9856\n",
      "\n",
      "Epoch 00035: val_loss did not improve\n",
      "Epoch 36/500\n",
      "150/150 [==============================] - 52s 344ms/step - loss: 0.1860 - acc: 0.9811 - val_loss: 0.2102 - val_acc: 0.9850\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.21946 to 0.21016, saving model to ../../saved_models/unet/unet_v4//model.hdf5\n",
      "Epoch 37/500\n",
      "150/150 [==============================] - 52s 344ms/step - loss: 0.1855 - acc: 0.9809 - val_loss: 0.1853 - val_acc: 0.9763\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.21016 to 0.18529, saving model to ../../saved_models/unet/unet_v4//model.hdf5\n",
      "Epoch 38/500\n",
      "150/150 [==============================] - 52s 345ms/step - loss: 0.1364 - acc: 0.9821 - val_loss: 0.1867 - val_acc: 0.9855\n",
      "\n",
      "Epoch 00038: val_loss did not improve\n",
      "Epoch 39/500\n",
      "150/150 [==============================] - 52s 346ms/step - loss: 0.1448 - acc: 0.9826 - val_loss: 0.2205 - val_acc: 0.9870\n",
      "\n",
      "Epoch 00039: val_loss did not improve\n",
      "Epoch 40/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 52s 344ms/step - loss: 0.1042 - acc: 0.9837 - val_loss: 0.2232 - val_acc: 0.9866\n",
      "\n",
      "Epoch 00040: val_loss did not improve\n",
      "Epoch 41/500\n",
      "150/150 [==============================] - 51s 340ms/step - loss: 0.1414 - acc: 0.9810 - val_loss: 0.1982 - val_acc: 0.9849\n",
      "\n",
      "Epoch 00041: val_loss did not improve\n",
      "Epoch 42/500\n",
      "150/150 [==============================] - 51s 342ms/step - loss: 0.1136 - acc: 0.9836 - val_loss: 0.2266 - val_acc: 0.9867\n",
      "\n",
      "Epoch 00042: val_loss did not improve\n",
      "Epoch 43/500\n",
      "150/150 [==============================] - 52s 347ms/step - loss: 0.1881 - acc: 0.9811 - val_loss: 0.1956 - val_acc: 0.9842\n",
      "\n",
      "Epoch 00043: val_loss did not improve\n",
      "Epoch 44/500\n",
      "150/150 [==============================] - 52s 343ms/step - loss: 0.1310 - acc: 0.9833 - val_loss: 0.2113 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00044: val_loss did not improve\n",
      "Epoch 45/500\n",
      "150/150 [==============================] - 52s 344ms/step - loss: 0.1398 - acc: 0.9828 - val_loss: 0.1809 - val_acc: 0.9849\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.18529 to 0.18090, saving model to ../../saved_models/unet/unet_v4//model.hdf5\n",
      "Epoch 46/500\n",
      "150/150 [==============================] - 51s 340ms/step - loss: 0.1315 - acc: 0.9828 - val_loss: 0.2071 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00046: val_loss did not improve\n",
      "Epoch 47/500\n",
      "150/150 [==============================] - 52s 344ms/step - loss: 0.1822 - acc: 0.9817 - val_loss: 0.1825 - val_acc: 0.9866\n",
      "\n",
      "Epoch 00047: val_loss did not improve\n",
      "Epoch 48/500\n",
      "150/150 [==============================] - 51s 339ms/step - loss: 0.1576 - acc: 0.9822 - val_loss: 0.1708 - val_acc: 0.9849\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.18090 to 0.17083, saving model to ../../saved_models/unet/unet_v4//model.hdf5\n",
      "Epoch 49/500\n",
      "150/150 [==============================] - 51s 340ms/step - loss: 0.1534 - acc: 0.9826 - val_loss: 0.1681 - val_acc: 0.9863\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.17083 to 0.16813, saving model to ../../saved_models/unet/unet_v4//model.hdf5\n",
      "Epoch 50/500\n",
      "150/150 [==============================] - 52s 345ms/step - loss: 0.1720 - acc: 0.9817 - val_loss: 0.1584 - val_acc: 0.9840\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.16813 to 0.15836, saving model to ../../saved_models/unet/unet_v4//model.hdf5\n",
      "Epoch 51/500\n",
      "150/150 [==============================] - 51s 340ms/step - loss: 0.1182 - acc: 0.9836 - val_loss: 0.1826 - val_acc: 0.9860\n",
      "\n",
      "Epoch 00051: val_loss did not improve\n",
      "Epoch 52/500\n",
      "150/150 [==============================] - 52s 345ms/step - loss: 0.1252 - acc: 0.9833 - val_loss: 0.1778 - val_acc: 0.9876\n",
      "\n",
      "Epoch 00052: val_loss did not improve\n",
      "Epoch 53/500\n",
      "150/150 [==============================] - 51s 342ms/step - loss: 0.1045 - acc: 0.9843 - val_loss: 0.1703 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00053: val_loss did not improve\n",
      "Epoch 54/500\n",
      "150/150 [==============================] - 51s 341ms/step - loss: 0.0974 - acc: 0.9846 - val_loss: 0.1722 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00054: val_loss did not improve\n",
      "Epoch 55/500\n",
      "150/150 [==============================] - 51s 342ms/step - loss: 0.0812 - acc: 0.9850 - val_loss: 0.1789 - val_acc: 0.9870\n",
      "\n",
      "Epoch 00055: val_loss did not improve\n",
      "Epoch 56/500\n",
      "150/150 [==============================] - 51s 341ms/step - loss: 0.1078 - acc: 0.9843 - val_loss: 0.1717 - val_acc: 0.9866\n",
      "\n",
      "Epoch 00056: val_loss did not improve\n",
      "Epoch 57/500\n",
      "150/150 [==============================] - 52s 343ms/step - loss: 0.1208 - acc: 0.9834 - val_loss: 0.1676 - val_acc: 0.9876\n",
      "\n",
      "Epoch 00057: val_loss did not improve\n",
      "Epoch 58/500\n",
      "150/150 [==============================] - 51s 342ms/step - loss: 0.0788 - acc: 0.9853 - val_loss: 0.1749 - val_acc: 0.9875\n",
      "\n",
      "Epoch 00058: val_loss did not improve\n",
      "Epoch 59/500\n",
      "150/150 [==============================] - 52s 345ms/step - loss: 0.1196 - acc: 0.9843 - val_loss: 0.1708 - val_acc: 0.9876\n",
      "\n",
      "Epoch 00059: val_loss did not improve\n",
      "Epoch 60/500\n",
      "150/150 [==============================] - 51s 340ms/step - loss: 0.1267 - acc: 0.9840 - val_loss: 0.1687 - val_acc: 0.9867\n",
      "\n",
      "Epoch 00060: val_loss did not improve\n",
      "Epoch 61/500\n",
      "150/150 [==============================] - 52s 345ms/step - loss: 0.1295 - acc: 0.9835 - val_loss: 0.1742 - val_acc: 0.9870\n",
      "\n",
      "Epoch 00061: val_loss did not improve\n",
      "Epoch 62/500\n",
      "150/150 [==============================] - 51s 342ms/step - loss: 0.0873 - acc: 0.9853 - val_loss: 0.1580 - val_acc: 0.9806\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.15836 to 0.15801, saving model to ../../saved_models/unet/unet_v4//model.hdf5\n",
      "Epoch 63/500\n",
      "150/150 [==============================] - 52s 344ms/step - loss: 0.0909 - acc: 0.9850 - val_loss: 0.1679 - val_acc: 0.9855\n",
      "\n",
      "Epoch 00063: val_loss did not improve\n",
      "Epoch 64/500\n",
      "150/150 [==============================] - 51s 341ms/step - loss: 0.0707 - acc: 0.9859 - val_loss: 0.1755 - val_acc: 0.9879\n",
      "\n",
      "Epoch 00064: val_loss did not improve\n",
      "Epoch 65/500\n",
      "150/150 [==============================] - 52s 343ms/step - loss: 0.0931 - acc: 0.9851 - val_loss: 0.1937 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00065: val_loss did not improve\n",
      "Epoch 66/500\n",
      "150/150 [==============================] - 51s 342ms/step - loss: 0.1000 - acc: 0.9849 - val_loss: 0.1894 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00066: val_loss did not improve\n",
      "Epoch 67/500\n",
      "150/150 [==============================] - 51s 341ms/step - loss: 0.0777 - acc: 0.9855 - val_loss: 0.2151 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00067: val_loss did not improve\n",
      "Epoch 68/500\n",
      "150/150 [==============================] - 52s 344ms/step - loss: 0.0922 - acc: 0.9854 - val_loss: 0.1871 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00068: val_loss did not improve\n",
      "Epoch 69/500\n",
      "150/150 [==============================] - 51s 343ms/step - loss: 0.0862 - acc: 0.9857 - val_loss: 0.1771 - val_acc: 0.9889\n",
      "\n",
      "Epoch 00069: val_loss did not improve\n",
      "Epoch 70/500\n",
      "150/150 [==============================] - 52s 344ms/step - loss: 0.0779 - acc: 0.9859 - val_loss: 0.1806 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00070: val_loss did not improve\n",
      "Epoch 71/500\n",
      "150/150 [==============================] - 51s 340ms/step - loss: 0.1397 - acc: 0.9838 - val_loss: 0.1737 - val_acc: 0.9871\n",
      "\n",
      "Epoch 00071: val_loss did not improve\n",
      "Epoch 72/500\n",
      "150/150 [==============================] - 51s 343ms/step - loss: 0.0840 - acc: 0.9859 - val_loss: 0.1728 - val_acc: 0.9852\n",
      "\n",
      "Epoch 00072: val_loss did not improve\n",
      "Epoch 73/500\n",
      "150/150 [==============================] - 51s 340ms/step - loss: 0.1202 - acc: 0.9848 - val_loss: 0.1940 - val_acc: 0.9876\n",
      "\n",
      "Epoch 00073: val_loss did not improve\n",
      "Epoch 74/500\n",
      "150/150 [==============================] - 51s 341ms/step - loss: 0.0956 - acc: 0.9855 - val_loss: 0.1475 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.15801 to 0.14746, saving model to ../../saved_models/unet/unet_v4//model.hdf5\n",
      "Epoch 75/500\n",
      "150/150 [==============================] - 52s 344ms/step - loss: 0.0876 - acc: 0.9854 - val_loss: 0.1988 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00075: val_loss did not improve\n",
      "Epoch 76/500\n",
      "150/150 [==============================] - 52s 347ms/step - loss: 0.0762 - acc: 0.9862 - val_loss: 0.1777 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00076: val_loss did not improve\n",
      "Epoch 77/500\n",
      "150/150 [==============================] - 51s 339ms/step - loss: 0.1656 - acc: 0.9836 - val_loss: 0.1988 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00077: val_loss did not improve\n",
      "Epoch 78/500\n",
      "150/150 [==============================] - 51s 340ms/step - loss: 0.1218 - acc: 0.9850 - val_loss: 0.1412 - val_acc: 0.9878\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.14746 to 0.14117, saving model to ../../saved_models/unet/unet_v4//model.hdf5\n",
      "Epoch 79/500\n",
      "150/150 [==============================] - 51s 341ms/step - loss: 0.0976 - acc: 0.9858 - val_loss: 0.1774 - val_acc: 0.9888\n",
      "\n",
      "Epoch 00079: val_loss did not improve\n",
      "Epoch 80/500\n",
      "150/150 [==============================] - 52s 343ms/step - loss: 0.0834 - acc: 0.9865 - val_loss: 0.1535 - val_acc: 0.9872\n",
      "\n",
      "Epoch 00080: val_loss did not improve\n",
      "Epoch 81/500\n",
      "150/150 [==============================] - 52s 344ms/step - loss: 0.0751 - acc: 0.9866 - val_loss: 0.1782 - val_acc: 0.9888\n",
      "\n",
      "Epoch 00081: val_loss did not improve\n",
      "Epoch 82/500\n",
      "150/150 [==============================] - 51s 343ms/step - loss: 0.1151 - acc: 0.9844 - val_loss: 0.1785 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00082: val_loss did not improve\n",
      "Epoch 83/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 51s 341ms/step - loss: 0.0943 - acc: 0.9859 - val_loss: 0.1630 - val_acc: 0.9888\n",
      "\n",
      "Epoch 00083: val_loss did not improve\n",
      "Epoch 84/500\n",
      "150/150 [==============================] - 51s 342ms/step - loss: 0.1043 - acc: 0.9857 - val_loss: 0.1740 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00084: val_loss did not improve\n",
      "Epoch 85/500\n",
      "150/150 [==============================] - 51s 342ms/step - loss: 0.0729 - acc: 0.9869 - val_loss: 0.1810 - val_acc: 0.9888\n",
      "\n",
      "Epoch 00085: val_loss did not improve\n",
      "Epoch 86/500\n",
      "150/150 [==============================] - 51s 343ms/step - loss: 0.0959 - acc: 0.9861 - val_loss: 0.1598 - val_acc: 0.9769\n",
      "\n",
      "Epoch 00086: val_loss did not improve\n",
      "Epoch 87/500\n",
      "150/150 [==============================] - 52s 346ms/step - loss: 0.1022 - acc: 0.9859 - val_loss: 0.1698 - val_acc: 0.9894\n",
      "\n",
      "Epoch 00087: val_loss did not improve\n",
      "Epoch 88/500\n",
      "150/150 [==============================] - 52s 343ms/step - loss: 0.1001 - acc: 0.9861 - val_loss: 0.1660 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00088: val_loss did not improve\n",
      "Epoch 89/500\n",
      "150/150 [==============================] - 51s 342ms/step - loss: 0.0726 - acc: 0.9865 - val_loss: 0.1690 - val_acc: 0.9900\n",
      "\n",
      "Epoch 00089: val_loss did not improve\n",
      "Epoch 90/500\n",
      "150/150 [==============================] - 51s 340ms/step - loss: 0.1052 - acc: 0.9858 - val_loss: 0.1613 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00090: val_loss did not improve\n",
      "Epoch 91/500\n",
      "150/150 [==============================] - 51s 341ms/step - loss: 0.0854 - acc: 0.9867 - val_loss: 0.1589 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00091: val_loss did not improve\n",
      "Epoch 92/500\n",
      "150/150 [==============================] - 51s 343ms/step - loss: 0.0571 - acc: 0.9878 - val_loss: 0.1709 - val_acc: 0.9897\n",
      "\n",
      "Epoch 00092: val_loss did not improve\n",
      "Epoch 93/500\n",
      "150/150 [==============================] - 52s 344ms/step - loss: 0.0990 - acc: 0.9865 - val_loss: 0.1528 - val_acc: 0.9866\n",
      "\n",
      "Epoch 00093: val_loss did not improve\n",
      "Epoch 94/500\n",
      "150/150 [==============================] - 51s 341ms/step - loss: 0.0864 - acc: 0.9865 - val_loss: 0.1707 - val_acc: 0.9898\n",
      "\n",
      "Epoch 00094: val_loss did not improve\n",
      "Epoch 95/500\n",
      "150/150 [==============================] - 52s 344ms/step - loss: 0.0888 - acc: 0.9868 - val_loss: 0.1435 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00095: val_loss did not improve\n",
      "Epoch 96/500\n",
      "150/150 [==============================] - 51s 343ms/step - loss: 0.0610 - acc: 0.9875 - val_loss: 0.1807 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00096: val_loss did not improve\n",
      "Epoch 97/500\n",
      "150/150 [==============================] - 51s 342ms/step - loss: 0.1126 - acc: 0.9861 - val_loss: 0.1691 - val_acc: 0.9897\n",
      "\n",
      "Epoch 00097: val_loss did not improve\n",
      "Epoch 98/500\n",
      "150/150 [==============================] - 52s 344ms/step - loss: 0.1025 - acc: 0.9860 - val_loss: 0.1353 - val_acc: 0.9895\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.14117 to 0.13532, saving model to ../../saved_models/unet/unet_v4//model.hdf5\n",
      "Epoch 99/500\n",
      "150/150 [==============================] - 52s 349ms/step - loss: 0.0828 - acc: 0.9868 - val_loss: 0.1593 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00099: val_loss did not improve\n",
      "Epoch 100/500\n",
      "150/150 [==============================] - 52s 347ms/step - loss: 0.0983 - acc: 0.9862 - val_loss: 0.1458 - val_acc: 0.9901\n",
      "\n",
      "Epoch 00100: val_loss did not improve\n",
      "Epoch 101/500\n",
      "150/150 [==============================] - 53s 351ms/step - loss: 0.0858 - acc: 0.9868 - val_loss: 0.1605 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00101: val_loss did not improve\n",
      "Epoch 102/500\n",
      "150/150 [==============================] - 52s 344ms/step - loss: 0.0549 - acc: 0.9879 - val_loss: 0.1582 - val_acc: 0.9899\n",
      "\n",
      "Epoch 00102: val_loss did not improve\n",
      "Epoch 103/500\n",
      "150/150 [==============================] - 52s 344ms/step - loss: 0.0541 - acc: 0.9881 - val_loss: 0.1660 - val_acc: 0.9900\n",
      "\n",
      "Epoch 00103: val_loss did not improve\n",
      "Epoch 104/500\n",
      "150/150 [==============================] - 51s 341ms/step - loss: 0.0867 - acc: 0.9872 - val_loss: 0.1449 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00104: val_loss did not improve\n",
      "Epoch 105/500\n",
      "150/150 [==============================] - 51s 343ms/step - loss: 0.0656 - acc: 0.9875 - val_loss: 0.1735 - val_acc: 0.9899\n",
      "\n",
      "Epoch 00105: val_loss did not improve\n",
      "Epoch 106/500\n",
      "150/150 [==============================] - 51s 342ms/step - loss: 0.0839 - acc: 0.9867 - val_loss: 0.1423 - val_acc: 0.9879\n",
      "\n",
      "Epoch 00106: val_loss did not improve\n",
      "Epoch 107/500\n",
      "150/150 [==============================] - 51s 340ms/step - loss: 0.0725 - acc: 0.9872 - val_loss: 0.1752 - val_acc: 0.9897\n",
      "\n",
      "Epoch 00107: val_loss did not improve\n",
      "Epoch 108/500\n",
      "150/150 [==============================] - 52s 345ms/step - loss: 0.1405 - acc: 0.9849 - val_loss: 0.1357 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00108: val_loss did not improve\n",
      "Epoch 109/500\n",
      "150/150 [==============================] - 52s 345ms/step - loss: 0.1010 - acc: 0.9861 - val_loss: 0.1662 - val_acc: 0.9899\n",
      "\n",
      "Epoch 00109: val_loss did not improve\n",
      "Epoch 110/500\n",
      "150/150 [==============================] - 51s 343ms/step - loss: 0.1169 - acc: 0.9861 - val_loss: 0.1950 - val_acc: 0.9902\n",
      "\n",
      "Epoch 00110: val_loss did not improve\n",
      "Epoch 111/500\n",
      "150/150 [==============================] - 52s 344ms/step - loss: 0.1026 - acc: 0.9861 - val_loss: 0.1748 - val_acc: 0.9904\n",
      "\n",
      "Epoch 00111: val_loss did not improve\n",
      "Epoch 112/500\n",
      "150/150 [==============================] - 52s 346ms/step - loss: 0.0540 - acc: 0.9880 - val_loss: 0.1802 - val_acc: 0.9901\n",
      "\n",
      "Epoch 00112: val_loss did not improve\n",
      "Epoch 113/500\n",
      "150/150 [==============================] - 52s 344ms/step - loss: 0.0730 - acc: 0.9874 - val_loss: 0.1672 - val_acc: 0.9904\n",
      "\n",
      "Epoch 00113: val_loss did not improve\n",
      "Epoch 114/500\n",
      "150/150 [==============================] - 51s 342ms/step - loss: 0.0799 - acc: 0.9874 - val_loss: 0.1563 - val_acc: 0.9898\n",
      "\n",
      "Epoch 00114: val_loss did not improve\n",
      "Epoch 115/500\n",
      "150/150 [==============================] - 52s 344ms/step - loss: 0.0622 - acc: 0.9878 - val_loss: 0.1632 - val_acc: 0.9902\n",
      "\n",
      "Epoch 00115: val_loss did not improve\n",
      "Epoch 116/500\n",
      "150/150 [==============================] - 51s 343ms/step - loss: 0.0915 - acc: 0.9868 - val_loss: 0.1622 - val_acc: 0.9904\n",
      "\n",
      "Epoch 00116: val_loss did not improve\n",
      "Epoch 117/500\n",
      "150/150 [==============================] - 51s 342ms/step - loss: 0.0893 - acc: 0.9874 - val_loss: 0.1517 - val_acc: 0.9907\n",
      "\n",
      "Epoch 00117: val_loss did not improve\n",
      "Epoch 118/500\n",
      "150/150 [==============================] - 52s 344ms/step - loss: 0.0515 - acc: 0.9885 - val_loss: 0.1613 - val_acc: 0.9906\n",
      "\n",
      "Epoch 00118: val_loss did not improve\n",
      "Epoch 119/500\n",
      "150/150 [==============================] - 52s 343ms/step - loss: 0.0824 - acc: 0.9871 - val_loss: 0.1665 - val_acc: 0.9907\n",
      "\n",
      "Epoch 00119: val_loss did not improve\n",
      "Epoch 120/500\n",
      "150/150 [==============================] - 51s 340ms/step - loss: 0.0680 - acc: 0.9877 - val_loss: 0.1580 - val_acc: 0.9906\n",
      "\n",
      "Epoch 00120: val_loss did not improve\n",
      "Epoch 121/500\n",
      "150/150 [==============================] - 51s 343ms/step - loss: 0.0608 - acc: 0.9883 - val_loss: 0.1626 - val_acc: 0.9908\n",
      "\n",
      "Epoch 00121: val_loss did not improve\n",
      "Epoch 122/500\n",
      "150/150 [==============================] - 51s 341ms/step - loss: 0.0776 - acc: 0.9877 - val_loss: 0.1228 - val_acc: 0.9853\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.13532 to 0.12282, saving model to ../../saved_models/unet/unet_v4//model.hdf5\n",
      "Epoch 123/500\n",
      "150/150 [==============================] - 52s 344ms/step - loss: 0.0679 - acc: 0.9878 - val_loss: 0.1625 - val_acc: 0.9894\n",
      "\n",
      "Epoch 00123: val_loss did not improve\n",
      "Epoch 124/500\n",
      "150/150 [==============================] - 52s 344ms/step - loss: 0.0623 - acc: 0.9882 - val_loss: 0.1863 - val_acc: 0.9906\n",
      "\n",
      "Epoch 00124: val_loss did not improve\n",
      "Epoch 125/500\n",
      "150/150 [==============================] - 51s 342ms/step - loss: 0.0982 - acc: 0.9872 - val_loss: 0.1710 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00125: val_loss did not improve\n",
      "Epoch 126/500\n",
      "150/150 [==============================] - 51s 339ms/step - loss: 0.0822 - acc: 0.9877 - val_loss: 0.1457 - val_acc: 0.9855\n",
      "\n",
      "Epoch 00126: val_loss did not improve\n",
      "Epoch 127/500\n",
      "150/150 [==============================] - 51s 341ms/step - loss: 0.0684 - acc: 0.9879 - val_loss: 0.1491 - val_acc: 0.9897\n",
      "\n",
      "Epoch 00127: val_loss did not improve\n",
      "Epoch 128/500\n",
      "150/150 [==============================] - 51s 340ms/step - loss: 0.0631 - acc: 0.9879 - val_loss: 0.1328 - val_acc: 0.9900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00128: val_loss did not improve\n",
      "Epoch 129/500\n",
      "150/150 [==============================] - 51s 340ms/step - loss: 0.0604 - acc: 0.9882 - val_loss: 0.1505 - val_acc: 0.9902\n",
      "\n",
      "Epoch 00129: val_loss did not improve\n",
      "Epoch 130/500\n",
      "150/150 [==============================] - 52s 344ms/step - loss: 0.0953 - acc: 0.9874 - val_loss: 0.1407 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00130: val_loss did not improve\n",
      "Epoch 131/500\n",
      "150/150 [==============================] - 51s 343ms/step - loss: 0.0815 - acc: 0.9874 - val_loss: 0.1496 - val_acc: 0.9902\n",
      "\n",
      "Epoch 00131: val_loss did not improve\n",
      "Epoch 132/500\n",
      "150/150 [==============================] - 52s 344ms/step - loss: 0.0995 - acc: 0.9870 - val_loss: 0.1494 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00132: val_loss did not improve\n",
      "Epoch 133/500\n",
      "150/150 [==============================] - 50s 331ms/step - loss: 0.0815 - acc: 0.9875 - val_loss: 0.1440 - val_acc: 0.9894\n",
      "\n",
      "Epoch 00133: val_loss did not improve\n",
      "Epoch 134/500\n",
      "150/150 [==============================] - 49s 329ms/step - loss: 0.0485 - acc: 0.9889 - val_loss: 0.1616 - val_acc: 0.9898\n",
      "\n",
      "Epoch 00134: val_loss did not improve\n",
      "Epoch 135/500\n",
      "150/150 [==============================] - 49s 328ms/step - loss: 0.0476 - acc: 0.9890 - val_loss: 0.1645 - val_acc: 0.9902\n",
      "\n",
      "Epoch 00135: val_loss did not improve\n",
      "Epoch 136/500\n",
      "150/150 [==============================] - 49s 326ms/step - loss: 0.0470 - acc: 0.9891 - val_loss: 0.1691 - val_acc: 0.9904\n",
      "\n",
      "Epoch 00136: val_loss did not improve\n",
      "Epoch 137/500\n",
      "150/150 [==============================] - 49s 325ms/step - loss: 0.0467 - acc: 0.9892 - val_loss: 0.1616 - val_acc: 0.9905\n",
      "\n",
      "Epoch 00137: val_loss did not improve\n",
      "Epoch 138/500\n",
      "150/150 [==============================] - 49s 324ms/step - loss: 0.0462 - acc: 0.9891 - val_loss: 0.1735 - val_acc: 0.9904\n",
      "\n",
      "Epoch 00138: val_loss did not improve\n",
      "Epoch 139/500\n",
      "150/150 [==============================] - 49s 325ms/step - loss: 0.0461 - acc: 0.9892 - val_loss: 0.1645 - val_acc: 0.9905\n",
      "\n",
      "Epoch 00139: val_loss did not improve\n",
      "Epoch 140/500\n",
      "150/150 [==============================] - 49s 326ms/step - loss: 0.0463 - acc: 0.9891 - val_loss: 0.1635 - val_acc: 0.9905\n",
      "\n",
      "Epoch 00140: val_loss did not improve\n",
      "Epoch 141/500\n",
      "150/150 [==============================] - 49s 327ms/step - loss: 0.0457 - acc: 0.9892 - val_loss: 0.1661 - val_acc: 0.9906\n",
      "\n",
      "Epoch 00141: val_loss did not improve\n",
      "Epoch 142/500\n",
      "150/150 [==============================] - 50s 335ms/step - loss: 0.0452 - acc: 0.9893 - val_loss: 0.1732 - val_acc: 0.9905\n",
      "\n",
      "Epoch 00142: val_loss did not improve\n",
      "Epoch 143/500\n",
      "150/150 [==============================] - 52s 345ms/step - loss: 0.0931 - acc: 0.9876 - val_loss: 0.2158 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00143: val_loss did not improve\n",
      "Epoch 144/500\n",
      "150/150 [==============================] - 51s 342ms/step - loss: 0.0577 - acc: 0.9884 - val_loss: 0.1722 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00144: val_loss did not improve\n",
      "Epoch 145/500\n",
      "150/150 [==============================] - 49s 329ms/step - loss: 0.0457 - acc: 0.9892 - val_loss: 0.1734 - val_acc: 0.9905\n",
      "\n",
      "Epoch 00145: val_loss did not improve\n",
      "Epoch 146/500\n",
      "150/150 [==============================] - 52s 345ms/step - loss: 0.0595 - acc: 0.9887 - val_loss: 0.1161 - val_acc: 0.9857\n",
      "\n",
      "Epoch 00146: val_loss improved from 0.12282 to 0.11608, saving model to ../../saved_models/unet/unet_v4//model.hdf5\n",
      "Epoch 147/500\n",
      "150/150 [==============================] - 49s 328ms/step - loss: 0.0477 - acc: 0.9889 - val_loss: 0.1617 - val_acc: 0.9904\n",
      "\n",
      "Epoch 00147: val_loss did not improve\n",
      "Epoch 148/500\n",
      "150/150 [==============================] - 49s 327ms/step - loss: 0.0497 - acc: 0.9891 - val_loss: 0.1628 - val_acc: 0.9900\n",
      "\n",
      "Epoch 00148: val_loss did not improve\n",
      "Epoch 149/500\n",
      "150/150 [==============================] - 49s 326ms/step - loss: 0.0447 - acc: 0.9895 - val_loss: 0.1767 - val_acc: 0.9902\n",
      "\n",
      "Epoch 00149: val_loss did not improve\n",
      "Epoch 150/500\n",
      "150/150 [==============================] - 49s 326ms/step - loss: 0.0443 - acc: 0.9894 - val_loss: 0.1718 - val_acc: 0.9904\n",
      "\n",
      "Epoch 00150: val_loss did not improve\n",
      "Epoch 151/500\n",
      "150/150 [==============================] - 51s 339ms/step - loss: 0.0441 - acc: 0.9895 - val_loss: 0.1638 - val_acc: 0.9904\n",
      "\n",
      "Epoch 00151: val_loss did not improve\n",
      "Epoch 152/500\n",
      "150/150 [==============================] - 49s 328ms/step - loss: 0.0679 - acc: 0.9885 - val_loss: 0.1539 - val_acc: 0.9909\n",
      "\n",
      "Epoch 00152: val_loss did not improve\n",
      "Epoch 153/500\n",
      "150/150 [==============================] - 49s 327ms/step - loss: 0.0472 - acc: 0.9891 - val_loss: 0.1510 - val_acc: 0.9905\n",
      "\n",
      "Epoch 00153: val_loss did not improve\n",
      "Epoch 154/500\n",
      "150/150 [==============================] - 49s 327ms/step - loss: 0.0435 - acc: 0.9896 - val_loss: 0.1556 - val_acc: 0.9908\n",
      "\n",
      "Epoch 00154: val_loss did not improve\n",
      "Epoch 155/500\n",
      "150/150 [==============================] - 49s 327ms/step - loss: 0.0437 - acc: 0.9895 - val_loss: 0.1552 - val_acc: 0.9905\n",
      "\n",
      "Epoch 00155: val_loss did not improve\n",
      "Epoch 156/500\n",
      "150/150 [==============================] - 49s 325ms/step - loss: 0.0431 - acc: 0.9896 - val_loss: 0.1498 - val_acc: 0.9905\n",
      "\n",
      "Epoch 00156: val_loss did not improve\n",
      "Epoch 157/500\n",
      "150/150 [==============================] - 49s 326ms/step - loss: 0.0431 - acc: 0.9896 - val_loss: 0.1707 - val_acc: 0.9909\n",
      "\n",
      "Epoch 00157: val_loss did not improve\n",
      "Epoch 158/500\n",
      "150/150 [==============================] - 49s 326ms/step - loss: 0.0427 - acc: 0.9896 - val_loss: 0.1535 - val_acc: 0.9901\n",
      "\n",
      "Epoch 00158: val_loss did not improve\n",
      "Epoch 159/500\n",
      "150/150 [==============================] - 49s 325ms/step - loss: 0.0421 - acc: 0.9898 - val_loss: 0.1735 - val_acc: 0.9908\n",
      "\n",
      "Epoch 00159: val_loss did not improve\n",
      "Epoch 160/500\n",
      "150/150 [==============================] - 49s 327ms/step - loss: 0.0423 - acc: 0.9899 - val_loss: 0.1629 - val_acc: 0.9905\n",
      "\n",
      "Epoch 00160: val_loss did not improve\n",
      "Epoch 161/500\n",
      "150/150 [==============================] - 49s 329ms/step - loss: 0.0425 - acc: 0.9896 - val_loss: 0.1630 - val_acc: 0.9909\n",
      "\n",
      "Epoch 00161: val_loss did not improve\n",
      "Epoch 162/500\n",
      "150/150 [==============================] - 53s 353ms/step - loss: 0.0815 - acc: 0.9881 - val_loss: 0.1781 - val_acc: 0.9905\n",
      "\n",
      "Epoch 00162: val_loss did not improve\n",
      "Epoch 163/500\n",
      "150/150 [==============================] - 49s 329ms/step - loss: 0.0422 - acc: 0.9897 - val_loss: 0.1653 - val_acc: 0.9907\n",
      "\n",
      "Epoch 00163: val_loss did not improve\n",
      "Epoch 164/500\n",
      "150/150 [==============================] - 49s 329ms/step - loss: 0.0516 - acc: 0.9894 - val_loss: 0.1607 - val_acc: 0.9905\n",
      "\n",
      "Epoch 00164: val_loss did not improve\n",
      "Epoch 165/500\n",
      "150/150 [==============================] - 49s 328ms/step - loss: 0.0419 - acc: 0.9899 - val_loss: 0.1636 - val_acc: 0.9906\n",
      "\n",
      "Epoch 00165: val_loss did not improve\n",
      "Epoch 166/500\n",
      "150/150 [==============================] - 51s 342ms/step - loss: 0.0545 - acc: 0.9892 - val_loss: 0.1645 - val_acc: 0.9904\n",
      "\n",
      "Epoch 00166: val_loss did not improve\n",
      "Epoch 167/500\n",
      "150/150 [==============================] - 50s 331ms/step - loss: 0.0712 - acc: 0.9885 - val_loss: 0.1401 - val_acc: 0.9913\n",
      "\n",
      "Epoch 00167: val_loss did not improve\n",
      "Epoch 168/500\n",
      "150/150 [==============================] - 50s 330ms/step - loss: 0.0414 - acc: 0.9900 - val_loss: 0.1519 - val_acc: 0.9908\n",
      "\n",
      "Epoch 00168: val_loss did not improve\n",
      "Epoch 169/500\n",
      "150/150 [==============================] - 49s 326ms/step - loss: 0.0410 - acc: 0.9900 - val_loss: 0.1550 - val_acc: 0.9909\n",
      "\n",
      "Epoch 00169: val_loss did not improve\n",
      "Epoch 170/500\n",
      "150/150 [==============================] - 49s 326ms/step - loss: 0.0408 - acc: 0.9901 - val_loss: 0.1544 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00170: val_loss did not improve\n",
      "Epoch 171/500\n",
      "150/150 [==============================] - 49s 326ms/step - loss: 0.0439 - acc: 0.9899 - val_loss: 0.1513 - val_acc: 0.9894\n",
      "\n",
      "Epoch 00171: val_loss did not improve\n",
      "Epoch 172/500\n",
      "150/150 [==============================] - 49s 325ms/step - loss: 0.0408 - acc: 0.9900 - val_loss: 0.1686 - val_acc: 0.9908\n",
      "\n",
      "Epoch 00172: val_loss did not improve\n",
      "Epoch 173/500\n",
      "150/150 [==============================] - 49s 325ms/step - loss: 0.0404 - acc: 0.9902 - val_loss: 0.1624 - val_acc: 0.9908\n",
      "\n",
      "Epoch 00173: val_loss did not improve\n",
      "Epoch 174/500\n",
      "150/150 [==============================] - 49s 326ms/step - loss: 0.0404 - acc: 0.9902 - val_loss: 0.1536 - val_acc: 0.9912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00174: val_loss did not improve\n",
      "Epoch 175/500\n",
      "150/150 [==============================] - 49s 326ms/step - loss: 0.0423 - acc: 0.9900 - val_loss: 0.1539 - val_acc: 0.9911\n",
      "\n",
      "Epoch 00175: val_loss did not improve\n",
      "Epoch 176/500\n",
      "150/150 [==============================] - 49s 325ms/step - loss: 0.0400 - acc: 0.9901 - val_loss: 0.1445 - val_acc: 0.9908\n",
      "\n",
      "Epoch 00176: val_loss did not improve\n"
     ]
    }
   ],
   "source": [
    "from train import train_nn\n",
    "\n",
    "m = train_df.shape[0]\n",
    "history = train_nn(model, \n",
    "                   train_gen, \n",
    "                   valid_gen, \n",
    "                   training_size=1200, \n",
    "                   batch_size=BATCH_SIZE,\n",
    "                   validation_size=valid_df.shape[0],\n",
    "                   output_path=model_dir, \n",
    "                   epochs=500,\n",
    "                   gpus = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xd4VFX6wPHvO5NOGpAAoYfem3RUUGyAihXFjrrYy1rWsj91dYuuvRcUbCvYsKCCgnSkht6lQwgkIZCE9GTm/P44k5BAEkJgSJn38zx5ZubOnTvv3Jnc955yzxFjDEoppRSAo6oDUEopVX1oUlBKKVVEk4JSSqkimhSUUkoV0aSglFKqiCYFpZRSRTQpKFVBIvKJiPyrguvuFJHzTnY7Sp1umhSUUkoV0aSglFKqiCYFVat4qm0eFZE1IpIpIuNFpKGITBORwyLyu4jULbb+pSKyXkRSRWSOiHQs9lxPEVnhed1XQNBR73WxiKzyvHahiHSrZMx/EZGtInJQRKaISGPPchGR10QkSUTSPJ+pi+e54SKywRPbXhF5pFI7TKmjaFJQtdGVwPlAO+ASYBrwJBCF/c3fDyAi7YBJwINANDAV+ElEAkQkAPgB+ByoB3zj2S6e1/YCJgB3APWBD4ApIhJ4IoGKyLnA88AoIAbYBXzpefoC4GzP54gErgFSPM+NB+4wxoQBXYBZJ/K+SpVFk4Kqjd4yxiQaY/YC84ElxpiVxphc4Hugp2e9a4BfjDEzjDH5wMtAMDAQ6A/4A68bY/KNMd8Cy4q9x1+AD4wxS4wxLmPMp0Cu53Un4npggjFmhSe+J4ABItISyAfCgA6AGGM2GmP2eV6XD3QSkXBjzCFjzIoTfF+lSqVJQdVGicXuZ5fyONRzvzH2zBwAY4wb2AM08Ty315QcMXJXsfstgIc9VUepIpIKNPO87kQcHUMGtjTQxBgzC3gbeAdIFJFxIhLuWfVKYDiwS0TmisiAE3xfpUqlSUH5sgTswR2wdfjYA/teYB/QxLOsUPNi9/cA/zbGRBb7CzHGTDrJGOpgq6P2Ahhj3jTGnAF0xlYjPepZvswYMxJogK3m+voE31epUmlSUL7sa2CEiAwVEX/gYWwV0EJgEVAA3C8ifiJyBdC32Gs/BO4UkX6eBuE6IjJCRMJOMIaJwBgR6eFpj/gPtrprp4j08WzfH8gEcgCXp83jehGJ8FR7pQOuk9gPShXRpKB8ljFmM3AD8BZwANsofYkxJs8YkwdcAdwCHMK2P3xX7LVx2HaFtz3Pb/Wse6IxzASeAiZjSyetgWs9T4djk88hbBVTCrbdA+BGYKeIpAN3ej6HUidNdJIdpZRShbSkoJRSqogmBaWUUkU0KSillCqiSUEppVQRv6oO4ERFRUWZli1bVnUYSilVoyxfvvyAMSb6eOvVuKTQsmVL4uLiqjoMpZSqUURk1/HX0uojpZRSxWhSUEopVUSTglJKqSI1rk2hNPn5+cTHx5OTk1PVoXhdUFAQTZs2xd/fv6pDUUrVQrUiKcTHxxMWFkbLli0pOahl7WKMISUlhfj4eGJjY6s6HKVULVQrqo9ycnKoX79+rU4IACJC/fr1faJEpJSqGrUiKQC1PiEU8pXPqZSqGrUmKRxPTr6L/Wk55LvcVR2KUkpVWz6TFHLzXSQdzsHlPvVDhaempvLuu++e8OuGDx9OamrqKY9HKaUqy2eSAp5qF2/MH1FWUnC5yp8Ma+rUqURGRp7yeJRSqrJqRe+jiiisiffGlEKPP/4427Zto0ePHvj7+xMaGkpMTAyrVq1iw4YNXHbZZezZs4ecnBweeOABxo4dCxwZsiMjI4Nhw4Zx5plnsnDhQpo0acKPP/5IcHCwF6JVSqmy1bqk8OxP69mQkH7McpfbkJPvIjjAieMEG2s7NQ7nmUs6l/n8Cy+8wLp161i1ahVz5sxhxIgRrFu3rqjb6IQJE6hXrx7Z2dn06dOHK6+8kvr165fYxpYtW5g0aRIffvgho0aNYvLkydxwg86wqJQ6vWpdUjie0zH5aN++fUtcR/Dmm2/y/fffA7Bnzx62bNlyTFKIjY2lR48eAJxxxhns3LnzNESqlFIl1bqkUNYZfUZuAduTM2gVVYfQIO9eDVynTp2i+3PmzOH3339n0aJFhISEMGTIkFKvMwgMDCy673Q6yc7O9mqMSilVGp9paPZmm0JYWBiHDx8u9bm0tDTq1q1LSEgImzZtYvHixV6IQCmlTg2vlRREpBnwGdAIcAPjjDFvHLWOAG8Aw4Es4BZjzArvxGNvvdD5iPr16zNo0CC6dOlCcHAwDRs2LHruoosu4v3336dbt260b9+e/v37n/oAlFLqFPFm9VEB8LAxZoWIhAHLRWSGMWZDsXWGAW09f/2A9zy3p5w3SwoAEydOLHV5YGAg06ZNK/W5wnaDqKgo1q1bV7T8kUceOeXxKaVURXit+sgYs6/wrN8YcxjYCDQ5arWRwGfGWgxEikiMVwLyZlFBKaVqidPSpiAiLYGewJKjnmoC7Cn2OJ5jEwciMlZE4kQkLjk5uXIxeG41JSilVNm8nhREJBSYDDxojDn6AoLSLhg45rhtjBlnjOltjOkdHX3ceadLj6OsjSullCri1aQgIv7YhPCFMea7UlaJB5oVe9wUSPBOLPZWa4+UUqpsXksKnp5F44GNxphXy1htCnCTWP2BNGPMPq/E4ykrGC0rKKVUmbzZ+2gQcCOwVkRWeZY9CTQHMMa8D0zFdkfdiu2SOsZr0Wj9kVJKHZfXkoIxZgGltxkUX8cA93grhuK8mRNSU1OZOHEid9999wm/9vXXX2fs2LGEhIR4ITKllDoxvnNFsxfbFCo7nwLYpJCVlXWKI1JKqcqpdWMflcWbbQrFh84+//zzadCgAV9//TW5ublcfvnlPPvss2RmZjJq1Cji4+NxuVw89dRTJCYmkpCQwDnnnENUVBSzZ88+5bEppdSJqH1JYdrjsH/tMYsFQ6tcFwF+DnCeYAGpUVcY9kKZTxcfOnv69Ol8++23LF26FGMMl156KfPmzSM5OZnGjRvzyy+/AHZMpIiICF599VVmz55NVFTUicWklFJe4DPVR6fL9OnTmT59Oj179qRXr15s2rSJLVu20LVrV37//Xcee+wx5s+fT0RERFWHqpRSx6h9JYUyzugF2BGfSnRYEI0igrz29sYYnnjiCe64445jnlu+fDlTp07liSee4IILLuDpp5/2WhxKKVUZvlVSEPFKm0LxobMvvPBCJkyYQEZGBgB79+4lKSmJhIQEQkJCuOGGG3jkkUdYsWLFMa9VSqmqVvtKCuUQvD909rBhw7juuusYMGAAAKGhofzvf/9j69atPProozgcDvz9/XnvvfcAGDt2LMOGDSMmJkYbmpVSVU5MDRv3oXfv3iYuLq7Eso0bN9KxY8fjvnZ9Qhp1QwJoHBnsrfBOi4p+XqWUKiQiy40xvY+3nk9VHwlCTUuCSil1OvlUUkB0lAullCpPrUkKFSkBeKtN4XTSko5SyptqRVIICgoiJSXluAdMKXckpurPGENKSgpBQd7rUquU8m21ovdR06ZNiY+P53izsiWm5+DvdJCRGHCaIjv1goKCaNq0aVWHoZSqpWpFUvD39yc2Nva4693/6lzaNgzl3eu7n4aolFKq5qkV1UcV5XQI+S6tk1dKqbL4VFLwdzpwuTUpKKVUWXwqKdiSgruqw1BKqWrLp5KCn0O0pKCUUuXwraTgFAo0KSilVJl8Kyk4HBRo9ZFSSpXJt5KCU6uPlFKqPL6VFLRLqlJKlcunkoJTG5qVUqpcPpUU/JwOCtzapqCUUmXxraTg0N5HSilVHh9LCg4KtE1BKaXK5GNJQbT6SCmlyuFTScGpXVKVUqpcPpUU/LVNQSmlyuVTScGpbQpKKVUun0oKduwjbVNQSqmy+FZS0IvXlFKqXD6XFPJdBmM0MSilVGl8Kyk47cfVwoJSSpXOp5KC0yEAOvuaUkqVwaeSgp8nKWi7glJKlc63koKn+kivVVBKqdL5VlLwlBR09jWllCqdbyUFp1YfKaVUebyWFERkgogkici6Mp4fIiJpIrLK8/e0t2IpVFhSyNekoJRSpfLz4rY/Ad4GPitnnfnGmIu9GEMJTofNgS4d6kIppUrltZKCMWYecNBb268Mf0/1kQ51oZRSpavqNoUBIrJaRKaJSOeyVhKRsSISJyJxycnJlX6zwusUtPeRUkqVriqTwgqghTGmO/AW8ENZKxpjxhljehtjekdHR1f6Df081Uc6UqpSSpWuypKCMSbdGJPhuT8V8BeRKG++Z1GXVK0+UkqpUlVZUhCRRiIinvt9PbGkePM9nU6tPlJKqfJ4rfeRiEwChgBRIhIPPAP4Axhj3geuAu4SkQIgG7jWeHn4Uv/C3keaFJRSqlReSwrGmNHHef5tbJfV00YHxFNKqfJVde+j00qvaFZKqfL5VlLQLqlKKVUuH0sK2iVVKaXK41tJoaj6SNsUlFKqNL6VFIoamrWkoJRSpfGppODUmdeUUqpcPpUU/HXmNaWUKpdPJQWnzrymlFLl8qmk4KfDXCilVLl8KykUdUnVkoJSSpXGp5KCzqeglFLl86mk4K/DXCilVLl8KiloSUEppcrnU0nBX4e5UEqpcvlUUnA4BBGdeU0ppcriU0kB7FAXWn2klFKl88Gk4NCGZqWUKoMPJgXRmdeUUqoMPpcUnE7RkoJSSpXB55KCn8OhbQpKKVUGH0wKosNcKKVUGXwvKTi195FSSpXF95KCQ/TiNaWUKoPPJQWnQxualVKqLD6XFPydDr2iWSmlyuBzScGp1UdKKVUmn0sKfk7tkqqUUmXxvaTgEK0+UkqpMvhcUtDqI6WUKluFkoKIPCAi4WKNF5EVInKBt4PzBn8d5kIppcpU0ZLCrcaYdOACIBoYA7zgtai8yOlwkK9JQSmlSlXRpCCe2+HAx8aY1cWW1Sh+DsGlbQpKKVWqiiaF5SIyHZsUfhORMKBGHln1imallCqbXwXXuw3oAWw3xmSJSD1sFVKNo2MfKaVU2SpaUhgAbDbGpIrIDcD/AWneC8t7dOY1pZQqW0WTwntAloh0B/4G7AI+81pUXqQzrymlVNkqmhQKjDEGGAm8YYx5AwjzXljeowPiKaVU2SrapnBYRJ4AbgTOEhEn4O+9sLzH389BXoGWFJRSqjQVLSlcA+Rir1fYDzQBXvJaVF4UFRrIwaw8rUJSSqlSVCgpeBLBF0CEiFwM5Bhjym1TEJEJIpIkIuvKeF5E5E0R2Soia0Sk1wlHXwkxEUEYA0mHc0/H2ymlVI1S0WEuRgFLgauBUcASEbnqOC/7BLionOeHAW09f2Oxjdle1ygiCID9admn4+2UUqpGqWibwt+BPsaYJAARiQZ+B74t6wXGmHki0rKcbY4EPvM0YC8WkUgRiTHG7KtgTJXSKLwwKWhJQSmljlbRNgVHYULwSDmB15alCbCn2ON4z7JjiMhYEYkTkbjk5OSTetMYT0lhn5YUlFLqGBUtKfwqIr8BkzyPrwGmnuR7lzZ2Uql9RY0x44BxAL179z6p/qQRwf4E+TvYn5ZzMptRSqlaqUJJwRjzqIhcCQzCHszHGWO+P8n3jgeaFXvcFEg4yW0el4gQExHMvnRNCkopdbSKlhQwxkwGJp/C954C3CsiXwL9gDRvtycUahgeSKKWFJRS6hjlJgUROUzpVToCGGNMeDmvnQQMAaJEJB54Bs8Fb8aY97HVT8OBrUAWp3GAvZiIYJbuOHi63k4ppWqMcpOCMabSQ1kYY0Yf53kD3FPZ7Z+MRhFBJKbn4HYbHI4aOS2EUkp5hc/N0Qy2W2qB23AgU7ulKqVUcb6ZFDzdUhP1WgWllCrBJ5OCXquglFKl88mkUDTUhXZLVUqpEnwyKUTVCcTPIezTbqlKKVWCTyYFh0NoGB5EQqpWHymlVHE+mRQA2jYMZfP+w1UdhlJKVSs+mxQ6xYSzNSmDnHxXVYeilFLVhs8mhc6NIyhwG7YkZlR1KEopVW34bFLo1NiO0LFhX1oVR6KUUtWHzyaFFvVCqBPgZENCelWHopRS1YbPJgWHQ+gYE856TQpKKVXEZ5MC2CqkjfvScbtPat4epZSqNXw6KXRuHE5mnovdB7OqOhSllKoWfDopdIqJAGDEm/MZ9MIskg7rFc5KKd/m20mhcTj3nNOakT2bsDc1m4lLdld1SEopVaUqPB1nbeR0CI9e2AGAhNRsvliym7uHtCHAz6dzpVLKh+nRz+PmgS1JPpzLtHWnZZpopZSqlnwnKSRugJnPQVbpczMPbhtNbFQdPl248/TGpZRS1YjvJIWD22D+K5C2p9SnHQ7hxv4tWLE7lbXxepWzUso3+U5SCImyt5kHylzlqt5NqRPg5BMtLSilfJTvJIU60fY2K6XMVcKD/LnyjKb8tDqBAxk6f7NSyvf4UFKob2/LKSkA3DSgJXkuN18u1e6pSinf4ztJISgSHH6QmVzuam0ahDKoTX2+XLZHh79QSvkc30kKIrZdIav8kgLANX2aE38omz+2HX9dpZSqTXwnKQDUiYLMstsUCl3YuSGRIf58uWwPuQUudqVknobglFKq6vlWUgipf9zqI4BAPydX9GzK9PX7GfLSHAa/NIdXp2/W6iSlVK3nW0mhTsWqjwCu69cMQWgSGcyl3Rvz5qyt/G3yGi8HqJRSVcu3xj6qE12h6iOANg3CWPXM+QT7OwGICPZn4tLdPDm8I/XqBHgzSqWUqjK+VVIIiYLcNCio2DUIIQF+iAgiwjV9muFyG6av3+/lIJVSqur4VlIovFahnAvYytK5cTjN64UwdZ0mBaVU7eVbSaECQ12URUQY3jWGhVsPkJqVd4oDU0qp6sG3kkLRUBeVu/5geNdGFLgNP63R4bWVUrWTjyWFypcUALo2iaBb0wj++dMGfl6TcAoDU0qp6sG3kkJIxcY/KouI8NmtfeneLIL7Jq3k+akbycl3ncIAlVKqavlWUigc/6iS1UcAkSEBfH5bP67t04wP5m1nxJvzmbkxEWP0wjalVM3nW0nB4ajwVc3lCfJ38vwV3fhkTB/cBm77NI7zXp3Lw1+vZndKVsmVZ/4T5vz3pN5PKaVOF9+6eA1sD6QKXsB2PEPaN2BQmyi+WraHWZuS+GVtAuk5+Xx4U+8jK22eCv7BMOSxU/KeSinlTb5VUgB7rcJJVB8dzd/p4Ib+LZhwSx/GDIpl1qYkktJzjqyQeaDMeaGVUqq68WpSEJGLRGSziGwVkcdLef4WEUkWkVWev9u9GQ/gGerCO0Nij+ptr3r+Znm8XeB22wvlsg955f2UUupU81pSEBEn8A4wDOgEjBaRTqWs+pUxpofn7yNvxVMksgWk7oLcjFO+6dioOvSLrcfXcZ4JenJSwbggJw3c2ktJKVX9ebOk0BfYaozZbozJA74ERnrx/Som9mxwF8DuRV7Z/LV9m7ErJYsXf9uMK6OwRGJsYlBKqWrOm0mhCbCn2ON4z7KjXSkia0TkWxFpVtqGRGSsiMSJSFxy8sn1HKJ5f3AGwvY5J7edMlzSrTHX9mnG+3O38fIPfxx5QtsVlFI1gDeTgpSy7OjO/D8BLY0x3YDfgU9L25AxZpwxprcxpnd0dPTJReUfDM37wfa5J7edMvg5HbxwZTf+el47tu/cdeQJbVdQStUA3kwK8UDxM/+mQImxIYwxKcaYwnGsPwTO8GI8R7QaAolrIeMkSx3luO2sWBr6HZnG87lvFvDrOh0zSSlVvXkzKSwD2opIrIgEANcCU4qvICIxxR5eCmz0YjxHxA6xtzu8U1oACA30o19Dd9HjQwcSmbh0TzmvUEqpque1pGCMKQDuBX7DHuy/NsasF5HnRORSz2r3i8h6EVkN3A/c4q14SmjcA4Ii4NcnYMr9Xuui2rO+C5extWiN/LNYtO0Ah3PyvfJeSil1Knj1OgVjzFRjTDtjTGtjzL89y542xkzx3H/CGNPZGNPdGHOOMWaTN+Mp4nDCqM+hWV9Y9QXM+pdX3ibGP5MkicKFg6s7h5LvMsz70zsJSCmlTgXfu6K5UKvBcO0X0OM6WD3JK+0LknWAyAZNMEERtAzJoW6IPzM26MxtSqnqy3eTQqEB90JBDiw76rq5rIPwyyNwcHvlt515gOCIhviF1MORfYhzOzRk1qYkMnMLTi5mpZTyEk0K0e2h3TBYOg4O7rDL3G74/g5Y9qFtc6jssNhZKXZin5B6kH2Ii7vHkJ5TQM9/zuDeiStIy9b2BaVU9aJJAWDI43YYig/OhjkvwJR7Yct0aHUO7JwP6yaf+DaNsQ3YIfUhuC5kH+Sc9g34cmx/ruvbnF/X7efq9xcSfyjr+NtSSqnTRJMC2N5Idy2ABp1gzvO28bnXTXDDZIjpAVPug1c7wfd3VXybeRngyvUkhXpFF6/1b1Wff1zamc9u7cu+tBwuf3cha+JTvfTBlFLqxGhSKBTZHG79FZ6IhycT4NK3bC+lKz6Ejpfa51dPhJRtFdteYTfXOlG2pJBV8ormgW2i+O6ugQQ4HYz6YBHLduowGEqpqqdJoTgRCAyDgDpHlkW3gys+gKs+BnHCis/K38bBHfDVDZCwwj4O8bQp5B0GV8k2hLYNw/jhnkE0CAvisclryC3QkVSVUlVLk0JFhcdAuwth1cRjDu5FjIGfHoCNP8GvT9plhSUFKHX8o+iwQJ4b2ZntyZl8NH+Hl4JXSqmK0aRwInrdDJlJsHFK6c+v+coOndGoK2R4rkcobGiGY5PCqomwaSpD2jdgeNdGvDlzC5v2pwOwcvehokbo2ZuS6PXPGRzIyEUppbzJ9+ZoPhltzoP6beH7OyFpI+xaCAkrbZuDXwCs/Raa9rEN1G/2stN+FnZJhZLDZxfkwtS/QWAotL2AZy7pzPJdhxjz8TKu7t2Mt2ZtoVfzuky+ayD/W7yLg5l5zN+SzOU9m1bNZ1dK+QQtKZwIpx/c+hu0PhfmvWTbDzpeApt+sQmh8+W27SEoAi56wXZpDQgtvaSwc4FtZzi8D7ZMp2F4EBNu6UN6dj5vztxC44hglu86xJLtKczbYq+2/mNrShV8aKWUL9GSwomqUx9GfwnxcRDTDfwCIT8HjBsCQo6s1+1q+we2SypAdrGSwuZp4B9ik8aKT6HDcDo3juDzm7uzZdcehvbtzsDnZ/HgV6vIdxlaR9fhj60HMMYgUtpUFUopdfK0pFAZItCsj00IAP5BJRPC0Qqrj9b/AIcTbYP05mm2xNHzBnuhXNpeKMil16wbuGbZNUT553FRl0bsS8umVVQdxgyKZV9aDjsOZJb9PkopdZI0KZwOgWFwzv/ZKUDf6gVTH4H0eGh3kb1IDoEvrrZtFXvjbIli5ReM6VDAssC7uL/Zds5sEwXAH1t1lFWllPdoUjhdBj8K9yyB2MGewffEdnGtF2urozKTYf13MPB+aNYPFr9Lj5VPES3pXCx/0KJ+CE0ig7VdQSnlVdqmcDrVbw2jJ9r5oTOTIbSBXd7uArh7EWydCV2uhM2/wNc3Iam7ILwJfjtmgnHTv1V95v6ZVLWfQSlVq2lJoSq0Ggxdryq5rE4UdL/G9nDqcLEdh6ndRXDBP22vpfhldG4czoGMPJIO51RN3EqpWk9LCtWRwwl/mQXOQMhNt8Nr/PkbHWPvBWDfyuk06Nod6raw67vywelfhQErpWoLTQrVlX+wvQ2OhOb94c9f6dL+al7xf4/us+bDyli4cz4sfg/m/tdeE9FhOMR0t4PxHdhiG7GDwqv2cyilahRNCjVBuwthxtOEjR/AZU4HCyNGMDB1GnwyAvathuYDIXkzbJ1R8nXxy+DqT2wX2uJS90DSBlu6aH2uLWnMeMa2ZzQ947R9LKVU9aNJoSbofSsEhkNAHZ5dDIszGzJ9cHeY8x9oeRbc8J09wB/aCfvX2usidi2E2f+G5Z9A7zFHtrV1pu3+ajwjsl4/GfavgcXvwJbf4K5F9rmsgxDRpCo+7fElrITdS6DfHccmPOV7Du2ERe/A+c8dKWGrStOkUBMEhhUd2MP3bWbb3G3kDPgrQVFt7HhMfgF2vXqx9g9s6WHXQvj1cdvFtWEnO83ojKchshlc/gH8/BB8PxbyMiG6IyRvhN//AdtmQepu24U2oI6dmrTPX2wvqaqWmQITr4GMRNt7q8sVFX9t4bSqhYnEGE0qtcHcl2DV/2zVac8bqjqaGk97H9UwHWPCcbkNWw9k2+qeoIjSV3Q44IpxtoTx7a2QlwVrv4HEdXDuU7ad4qoJdrkzEG783vZ2WvwOpCfYYTt+e9JeaLdlOky+HQ7tOr0ftpDbBUs/tNd3/HiPLcVEtYOpj5YcZPBoBbnwx5uQ4enGO/NZeG+QbXPZMR9eam27B9dmKz63pcXaKjPF/q7B/kYqO5+6KqJJoYbpGBMGwIZ96cddd+F+B0/KfZC8kfRXz4Cf/wqNukFnz9l1gw5w0w9w43cQHsPmXk8xVc5i9xU/wNmP2CHC102GM8ZgcJP6+Y0UZJUydWjmAVt837Xo2Lkm3O7yD9zH43bZK72nPgK/PAx/ToOhT9u2kpxUW2pIWAkHttoDfYFneHFjbAKZ8RTMfdEuXzYBktbDF1fBV9dDVoqderU0uRl2SJLcjJLLc9Jg6+/gKqj8ZyouYeWx73Gq7F9n5/f46QGImwC5h20b1Kk8cG6ZAZ9cDIkbTt02T8SKT+20t33+AvtWwd7lVRMHnLrfRBXT6qMapkX9OgT7O5mzOYmrz2jK/xbv4qMFO3jnul60axjG+AU7OLNNFF2bRvC/JbuYn9GeqKB76Jm1kEHdBhNw9oO2FFGoef+iu9PiA3g9+y4e2B3KX8+5z56BBUXC8Jf5PbcjQ9c+RubrfQi76GmI6U5B/fb8vC6Ri1ffhd+uBXYjIfWhx/VQrxWkbLXjPaXH27aPrldD096wZ6kd+6luS2jc03atTU+AHfOgwwjbsG6MHRbkj9ft7blP2aqigztsTyuHAy57D6Y9BuOGHPk8QZG28Tw/C/78FUIbwZqv7efMTYPet0HceKgTbdf781dPQ/vTthR13TewZ4lNNgXZdtDCy9+3VXCz/mVHwy3IttsZ8YqNO/sgRHdtGLHXAAAePUlEQVSw75mRbC9SLKyWcrth+yxo0tv2JMtItlVfjbrA7sUw4UKIaA6XvGarAk9E8p+w6WcY9IB9/OO90Pkyu//cbvjlIfueMT1sQp32GLjyoM35cNm7Ry6erKyDO+Db2+x+HX8BjPrkxD9DabIP2SrNiKb2hGPph9Cws71+p/C3awzsXWFLj7Fnw3nPwOpJMO1v9sSn69XQclDJ7SZthCn32zaz1udCj+vs77Qi9iyDqDZ2xONdi+yJwYB7bPud2w2z/mlPjM5+BM58yF5vVNnP7hdsx1OrImJqWHGrd+/eJi4urqrDqFKvTN/MW7O2cmHnhkzfkIgAEcH+tIoOZfmuQ/RtWY/Pb+9Lr+dmcGmPJozu24xL3/6D56/oyui+zcvc7uhxi1m0PYUOjcL49cGzIT8bHP7g9GPYG/MJSlzB834f0sGxB4AU/0YszGnJJc7FMOwlCGtoE8mmqfYfT5z2ny+mmz2Ypharfqrb0h4g84sN8OfwB3cBnPUQbJttpzQNqQ+DH4d+Y0sPOifNTlYUEGr/QddNtmeLeZn2wNB+GHx6iR2p1uGEhzbBjrkcDorh3W+n8Vjqczb2Xx+zVWZdR9mJkgLDof9d9kATv8xu35VnDyRgq2RaD7WJzJ3vid1TSoruAN1H2wPO0nGwc76deOmSN+Drm21SGDvXlmISVtrPeGAL3P67TZqpu+37B0dCdqpt4wltYA9qKz6z83ec+SB8MNiWfC59CxCYcq+d7+OepbYENOVeGPmOHdJ96qP2gBZc15acAkNtw2zdlrDuOxt7aCPocxvUaQAbfrB/e5ZCyzOh27W2x1qdaOgxGgryYPx5tpF39Fd2+we3wR3zIKrtif2gjbFn/LsX28S8fx1g7IlE0gZbogOo3wbqxtrvIWUrpO+1Sfu6ryH2LJu0F75lS5dNesFt0+1vbNlHdgSB1ZPs91gv1o5ybNz2JOTc/4MGHcuOb/VXtu0tqp3dZ5Nvh7wMuy/bDbP7YPdCaNjFxh/dwVbFOgNsnNmHbNfwEa/ZUZbLsnuxpxOIsd3L+91pP8cpIiLLjTG9j7ueJoWaxxjDw9+s5rsVe+nVPJLnr+jGzROWcigrjwGt6zNnczL/HNmZp35cz/ibe3Nuhwac/9o8IoP9+faugaVuM7fARbd/TCfI30ladj5zHx1Ci/p2rurN+w9z4evzeOyiDny/fBd+KZvoG7Kfq/J+pItjJ7/5ncMFT36HFJ7FZR6w1TWhDY+cMbnd9h8kYYX9525yhv3nPbTjyEGwQUeYfJs9ew9vAkMetwfpkzlrMsYOQnhwO/S9A4a/CMDMjYnc/elC1gTfSaAU2H/grlfbg5Mz0F482KiLTYxTH7FVYBf8y5YC3G749hY77WrPG+1BM3GdPUgEhMLKz201DdjP1ftWez2JK9cmp8K5wA/thKHPQN+/2EmZotrBJa/bkk9AHfvcvJfsPioU2sjO6tdqiC1BhTexB0mHn401JxUufduWfKLbwy1TS5YMwSaXnx6wJSKwMQeE2gOnf7A9Q0/eBGExNkltm20PgmAT/QOrbFXdj3fDqM+g00hbYnpvIEQ2h1Gf23acxj3t979vjT0wxp5tfxfbZnn2RV1o2te2XS3/2H62Bh2g+QD7Pqu+sL+hEa/Y5LB6kt2OOKBea2gx0NOudtS1OHNfhNn/gYc3w4LXYMl7tgTZtLdNkmGN4PB+WwJZOs5+tjbn2f1/aKctgRi3TdbN+9l2mUZdbeLOO2xLdpe+CYvehqRN9jP2vxv6jrXjly390J5IGDdEtrCjFexbbUu4134BcR/bE4+UbYCxv5H6rWHDjxDe2H7+DVNsCaxxL5v4otvBmX+1+7eSNCnUcvkuNz+s3MsFnRoREeLPgYxcsnJdBPo7GPD8TAL9nBgMq56+gCB/J+/N2cZ/f93EbWfGsmznQV6/pgetokNZuO0AThGcDuGq9xfx1MWd+OfPG3hyeAd6NKtLgJ+D39bvZ9y87Sx5cigFLsPXcXtYufsQZ7apT7PMtdw7B364/1w6NT4FF8q5Cuw/TIuBlepemJSew/70HLo1jTyycMFrtlfV7TPtgQF4bcafvDFzCx8EvMaFjmW2Cubcp2wCiB18/F5Nbpc9gy2rCiYzxR5gIptDaLTtCjz/VRj2X0jZAt/cYg9Uf11nE8TSD+17hza01Vkh9e16dRrYA5nTz67fqKs9m9w+207wdNbDMO4cwMAtv2B+uAtS40EEuXO+rXYpNX63bTNy5duz5YAQe5Ca8bQt0Q160LY9ORw2IcbH2YPb+PNt/f32ObbkdeeCI1VlG3+2bTWF2g+3U9h+c4utcmvW3+6TwqlqwSYzd4E94A195tT0BkvcAO8NgAufh7kv2AP+VRNKXzczBRa8ar+fg9vsQblZPzssfupu24OvXmu49Vd7YjH/FTjvH8cvDeVnA3LkhKbw+w1rDIcT7DajO9h9mH3IJuG6sTZphDaAnHRbwtky3b5+73J7gjP0aRh0f6V2iyYFHzbm46XM3pzMeR0b8tHN9jewPy2HgS/MxG2wCaBXU54c0ZEzX5hFgdtwWc/GTFq6hxVPnc+N45ewef9hCtz2t+F0CGe1jeKTMX2Pea+UjFz6/mcmd5zdir9d1KFS8WblFbAhIZ1dKVmc1S6KBmGVLxncO3EFMzcmsfyp8wgJ8JRSCvLsWXHsWUXr3frJMtbEp9IlaymvRnxNvXtn2oPe6TL3JXtg6XzZkRjf6WMPmtdPtm0gKz+3Z+HhjUu+NicNFr9vSyCh0TDvZduIfP6zbPjhRTqt+jdrWtxEtzFvnfq4vxtrqwiN23Zr7n5tyedXTbQN53mHYeY/AQMNOttqtyXv2+qqQQ/az5QWb+vmo9vbz3KqugcXlg4zkmwp4OafbCmlIq87Ooa8TFtqOdk6fmNsKXjHfBj+0pHvvaLS4m2pse2FtmqpEiqaFLShuRYa1buZJykcOYttFBHEF7f3Jyo0gE8X7eTrZfEE+Ts4nFtAsL+TSUv30K5hKPXqBHDzgJZ8vHAnNw1oQW6+i8kr9nL7maU3yNUPDWRg6/p8HRfPrE1JOB3CxNv7ExFy7FhMeQVuJi3dTd/YenSMCSclI5eXp29myqoEMvPsxXQjusXwznWVq0fNd7mZuzmZ7HwXczcnc2HnRny3ci9D2kcTVSwhGGNYE5/G4HYNOJBxPsP292NuQF1K+7f32kx3gx8t+dgvAK6dZJNCW09jbf+7Sn9tUAQMeezI47MfKbr7pes8DuWlsXbfIGa43GR59mtE8CkaG2vgfbDmK1tt1eXKY58vbHMBiGoP67+HYS/auvSB95Zct2En71z7ImIbpRe+adt1Wp51/NcUvu5oAXVOXUxXjrfJ1OE88ddHNLVtUqeBdkmthS7s3Ih3ruvFFb2allg+oHV92jYM49ZBseS53Hy6aBfndWzA30fYRrZ+sbYRbFSfZkx74CxG923OLYNi+em+Mzmzbdln0Vf0asKBjFz8nMKWxAzGfh5HboGrxDq7UjK56v2FPDNlPX//fi0A/5m6iW+XxzOsawzjb+7N6L7N+XXdfvalZVfqc8ftPMThXNstcNq6/Uxdt49HvlnNnZ8vp8DlLlpvf3oOBzJy6dY0gjsGtyIxPZfnfj62S+W3y+MZ9MIs/kw8fMKxuNwVL4FvSTzM7Z/GMTctutJngYXmbU9jUcg57Ew3vDx9M+e9Opehr8xh8fZTNA9Ho64w5Al7tnu8QRg7XgxXjS+/cdVbOo20t2fcUn0uUBSpXEI4zTQp1EIOhzCiWwwBfqV/va2iQ4tKEfee25br+jbn8WEduGVQy0q932U9mrDs7+fx831n8dLV3Viy4yAXv7mACQt2kJPvIiuvgJsnLGVXShYXd4thxe5UZmxIZMrqvVzfrwUvX92doR0bcveQ1riN4X+Lj71IzuU2zPszmVembyY9J7+UKGD25iQCnA4u6d6YmRsTef33LUSG+BO36xCv/76laL018WkAdG0awcDWUdwxuBUTl+zmh5V7i9YpcLl5bcafJKTlMObjZXw0fzsDnp/Jh/O2A7ZUMnXtPu7+YjnXjlvEI9+sZmuSbYx9+bfNDHh+ZtFjsFVkXy7dTUbusX3Zxy/Ywe8bE7l5wlLu8CTUAs/2U7PyKvw97DmYxc6ULO4a0pp2DUP5YO52ApwOwoP9uf6jJczalFjhbZVryOO2HaKY3SlZrNpTyjUsxWTnuSisrt6adJgvluzCfQLJ84Q07Q03TYF+ZZS2VJm0+shHPXNJZy7p3pgezWyD7J2DW1d6WyJCdJidr3pkjyb4ORyMm7eN537ewK/r9tOifgg7U7KY+Jd+dG0SwZzNyTzw5UoK3IYxxRJRs3ohnNexIROX7CY9u4BAPwePXNiewzkFXDtuEduSbffV9QnpvDaqB/+euoGDmflc1KURw7s2YtamJPq1qsdVZzTlp9UJbE3K4K3RPZm/JZm3Z28lbtdB7hrShrXxaTgdQqcY2zD+yAXtWbHrEA9/s5qkwzn85axWTFu3n72p2TwwtC0fzt/Ov37ZSHiQH6/M2MzwbjE8P3UjP6/ZR3RYIM3rhTBt7T5W70nlnet78cG8beS7DDeNX8K3dw2kcWQwH8zdzhszt/DunG3cc05rDmXlM6BVfTrEhDF17T5GdIuhU0w4L/22mQe/XEV2vos5m5NpEBbIi1d1Y0j7kg3aGxLSadcwFD+no+hAWzhV69lto2jXMJSJS3bz7KWdCQ5wcvFbC/hg7nbO7dCw1O9wa9Jhnv1pA5EhAZzbIZrLezYtdb3SuNyGMZ8sZceBTJ69tDM3Dmh5zDqpWXkMfWUusVF1uOfcNjz01SoOZeWzZk8az1/RFYej8mfzy3Ye5Kkf1vHprX1pGF6sErDV4Epv05dpQ7PymimrE3jk69XkudyMGdSSZy6xPWH+MWU9nyzcyYWdG/LBjSXbvZbuOMioDxYRGuhHRm4Bw7o0IvlwLusS0vjvld1IycjjuZ83EBbkR3aeiwZhgSSk5RAe5Ed6TgFPX9yJGwe0oPe/fqdBWCC/Png2BW43ny7cycd/7GRfWg7B/k5aRtVh2gNH6pozcgt49JvVTFu3nzNa1CU1Kw9j4PeHBrMuIY2DmXm0aRDK0FfmEhUayN7UbB46vx33nNMGp0OYvTmJMR8vIyLYn3yXm3eu78X9E1fSKroOX44dwFkvzqJxZDCHsvLYc9BWj0WHBfLohe3527dr+HhMH85p34AP523n31M34nQI953bhqlr97ElKYMf7h5Ed08C/3lNAvdOXMnovs34+4hO3PbJMpIO5xIe5Mf+9BwWPzH0mHaQt2dt4eXpfzL/b+fQrF4IfyYe5rsVe2kdXYcrezXlqvcXsnn/YcKC/Ek8nMOMv55NZEgAd3y+nEu6xXDzwJZF21yw5QCRIf50aWKHWPlx1V4e+HIV7RqG8mdiBmMGteSJYR1LlFRfmLaJD+ZtI9jfSVaei5iIIC7o1JBPF+0q8duojDs/X86v6/dz04AWPDeyS6W3czK2JmXw71828PLV3akfGlglMRyP9j5S1cLi7Sn8smYffx/RkSB/W5+652AWYz5ZxqujupfsOuqRmpVHeJA/E/7Ywb9+2QjAW6N7ckn3xhhjePanDUxdu4+3Rvekb2w94nYd4qP521m64yA/3XcmTeuGsHzXISJD/GkdHVq03bwCNx/O386bM7dwXb/mxxyIjDFMXLqbd2dvY29qdqkX+706fTNvztrKsC6NePf6XiUOvg9/vZrJK+J56Px23D+0LVNWJ3D/pJX0i63Hkh0H+fy2vvRuUY/dB7NIz8nn2nGLcQiEB/mz+Mmh+DvtQfTb5fE0qxtMv1b1OZyTz7mvzKVJZDDf3TWQfLeboa/MJSUjj+x8F40jgkg8nEtMRBDxh7K5omcTXr2mxzH7dG9qNmf+dxb3n9uW1Kw8Pl10pIpucLto5v6ZzCtXd+ecDg0Y9MIshnVthL/DwVdx9kLFkT0a89fz2jFjQyL/nmq/k2FdGjG6b3P+8dN6ApwOfrrvTP79y0Y+WbiTHs0iuXNwa85sG0VWbgFnvzSbizo34t5z2zJ+wQ7uGtya5vVDeOqHdfxvyS6mPXAWHRqdeJfmg5l59PvP7/g7HRS4DLMfHUKTyBPryrxi9yGy81wMalP53mf3TFzBL2v2ce85bXjkwvbHPG+M4d0520hIzeZfl3XxTueF49CkoGqFj+ZvJ8DPwU1HVUm43abSVQ7pOfkE+jkI9Cu90a/A5Wbt3jR6NIs85p83J9/FlNUJjOgaQ53AkrWvh3Py+Wn1Pq7o1YQgfyfGGG77NI5Zm5Jo0yCUGX89u8T2XvptE+/M3nbcM9zJy+N5+JvV/O2i9mTkFPDunG18dmtfvo7bw7R1+3nj2h6c17Eh3y6P56y2UUUXHR7tho+WsHh7CgVuw00DWnDPOW147ucN/LJmH/1b1WPSX/ojIvzz5w18snAnbmO4dVAsEcH+vDFzS1Hj+YiuMbRpEMr4BTuK2kjeu74Xw7rGANiTgB/Wkppl237CAv3Iyncx86HBtIwqGVtqVh5nvzibns3r8umtx3Z5Pp4JC3bw3M8b+PiWPtzx+XKGd23EK6N6kJCazRszt3Bp98ac3S66zNdvTcpg5NsLyClwM/7m3sdU01XErpRMznl5Dv5OB4F+DhY+MZTQYr8Nl9vwfz+sY9LS3QC8fk0PLut5+oel16SgVDWwNzWb0eMW87eL2nNxt5LXG+QWuHh1+p/c0L8FzeqFlLkNt9sw6oNFxO06BMCQ9tF8MqYvbrchOSO3ZD16OQqreW4e0IJ/XNoZEaHA5earuD0M7dCQRhF2O/vTcjj7xdmEB/sz+5HBtkopPYdv4vbgcsO959oqs5x8Fwu2HCAhLZsb+rUokaTzXW7idh5i2c6D7DyQSfdmkdw8sGWpcY2bt43/TN3EiK4xhAf7EejnJNDfJu1APwdOh+DnsBdY+jkdRff9ncI7s22V1E/3ncmLv27i3Tnb6N4skh3JGaTn2IR1bocGGGMI8ncysE0UzeoG4+ew231myjoOZOTRICyQPQezeHx4R7o0DickwA+H2PYyh4BDBIeI7UDkEJye5SLCK9M3892Kvbx9XU/Gfr6cy3s2YceBTMKD/bmpfwven7uNuF2HuOec1izYcoC9qTnMfHhwUTdht9uwNzWbPJebFvVC8HOW7CCS7+k55+88uX5BmhSUqiZOxbUOOfkuVuw+RE6+i17N6xIZElCpONYnpNMpJvy4paxZmxKJDg2ia9MyhmY/hXLyXdw3aSWb9qeTk+8mN99FToGbvAL38V8M/OfyrlzXrznGGL5fuZd/TFlPi/p1eO2a7ny/ci/fr9hL3ToBpGblsze1ZHdnEfjs1r60axjG6HGL2X4gs4x3Kd/ovs14/opuXPPBIpbsOEhsVB3SsvM5mJlHWJAf/7qsCyN7NGFtfBoj31mAn8NBgCfh5RW4yc63XbgDnA7CgvyKEmG+23AgIxcBYiKCGTOoJbefVcFB/I6iSUEpVaO53YYCt8HlNuS73bhcxR673LjcBhFoXi+kRNLNznMVHXCLM8awKyWLlMw8CjyvbxAeRJsGoUXP7z6YxZ+JGeS73LiNwW3scpfbYAyeZXZ54a1gq9Tq1gkg/lAW6xPSGdqhATkFbn5ancDgdtE0LtbOMX39fpbvOlT0WZwOoU2DUAKcDrYkZXA4Jx9XsecahgdhjGHPoWyGtI9mZI/KVT1Vi6QgIhcBbwBO4CNjzAtHPR8IfAacAaQA1xhjdpa3TU0KSil14iqaFLx28ZqIOIF3gGFAJ2C0iHQ6arXbgEPGmDbAa8B/vRWPUkqp4/PmFc19ga3GmO3GmDzgS2DkUeuMBD713P8WGCpV0VdLKaUU4N2k0ATYU+xxvGdZqesYYwqANOCYgVJEZKyIxIlIXHJyspfCVUop5c2kUNoZ/9ENGBVZB2PMOGNMb2NM7+josvscK6WUOjneTArxQLNij5sCCWWtIyJ+QARwErO8K6WUOhneTArLgLYiEisiAcC1wJSj1pkC3Oy5fxUwy9S0PrJKKVWLeG2UVGNMgYjcC/yG7ZI6wRizXkSeA+KMMVOA8cDnIrIVW0K4tuwtKqWU8javDp1tjJkKTD1q2dPF7ucAV3szBqWUUhVX465oFpFk4NhZWComCjhwCsPxtpoUb02KFWpWvDUpVqhZ8dakWOHk4m1hjDluT50alxROhojEVeSKvuqiJsVbk2KFmhVvTYoVala8NSlWOD3x6nScSimlimhSUEopVcTXksK4qg7gBNWkeGtSrFCz4q1JsULNircmxQqnIV6falNQSilVPl8rKSillCqHJgWllFJFfCYpiMhFIrJZRLaKyONVHU9xItJMRGaLyEYRWS8iD3iW/0NE9orIKs/f8KqOtZCI7BSRtZ644jzL6onIDBHZ4rmtWw3ibF9s/60SkXQRebA67VsRmSAiSSKyrtiyUvelWG96fsdrRKRXNYj1JRHZ5InnexGJ9CxvKSLZxfbx+6cz1nLiLfO7F5EnPPt2s4hcWA1i/apYnDtFZJVnuff2rTGm1v9hh9nYBrQCAoDVQKeqjqtYfDFAL8/9MOBP7MRE/wAeqer4yoh5JxB11LIXgcc99x8H/lvVcZbyO9gPtKhO+xY4G+gFrDvevgSGA9OwIwz3B5ZUg1gvAPw89/9bLNaWxderRvu21O/e8z+3GggEYj3HDGdVxnrU868AT3t73/pKSaEiE/5UGWPMPmPMCs/9w8BGjp17oiYoPmnSp8BlVRhLaYYC24wxlb0i3iuMMfM4dnTgsvblSOAzYy0GIkUk5vREWnqsxpjpxs6HArAYOyJytVDGvi3LSOBLY0yuMWYHsBV77DgtyovVM/nYKGCSt+PwlaRQkQl/qgURaQn0BJZ4Ft3rKZZPqA7VMcUYYLqILBeRsZ5lDY0x+8AmOqBBlUVXumsp+U9VXfctlL0vq/tv+VZsSaZQrIisFJG5InJWVQVVitK+++q8b88CEo0xW4ot88q+9ZWkUKHJfKqaiIQCk4EHjTHpwHtAa6AHsA9bfKwuBhljemHn4L5HRM6u6oDKI3b49kuBbzyLqvO+LU+1/S2LyN+BAuALz6J9QHNjTE/gIWCiiIRXVXzFlPXdV9t9C4ym5AmN1/atrySFikz4U6VExB+bEL4wxnwHYIxJNMa4jDFu4ENOY1H2eIwxCZ7bJOB7bGyJhVUZntukqovwGMOAFcaYRKje+9ajrH1ZLX/LInIzcDFwvfFUenuqYVI895dj6+jbVV2UVjnffXXdt37AFcBXhcu8uW99JSlUZMKfKuOpLxwPbDTGvFpsefG64suBdUe/tiqISB0RCSu8j21oXEfJSZNuBn6smghLVeJMq7ru22LK2pdTgJs8vZD6A2mF1UxVRUQuAh4DLjXGZBVbHi0iTs/9VkBbYHvVRHlEOd/9FOBaEQkUkVhsvEtPd3ylOA/YZIyJL1zg1X17ulrWq/oP22vjT2xG/XtVx3NUbGdii6lrgFWev+HA58Baz/IpQExVx+qJtxW2l8ZqYH3h/gTqAzOBLZ7belUdqyeuECAFiCi2rNrsW2yy2gfkY89WbytrX2KrON7x/I7XAr2rQaxbsXXxhb/d9z3rXun5fawGVgCXVJN9W+Z3D/zds283A8OqOlbP8k+AO49a12v7Voe5UEopVcRXqo+UUkpVgCYFpZRSRTQpKKWUKqJJQSmlVBFNCkoppYpoUlDqNBKRISLyc1XHoVRZNCkopZQqoklBqVKIyA0istQzVv0HIuIUkQwReUVEVojITBGJ9qzbQ0QWF5tPoHDugzYi8ruIrPa8prVn86Ei8q1nDoIvPFe0K1UtaFJQ6igi0hG4BjvoXw/ABVwP1MGOn9QLmAs843nJZ8Bjxphu2CtlC5d/AbxjjOkODMRerQp2FNwHseP3twIGef1DKVVBflUdgFLV0FDgDGCZ5yQ+GDsgnZsjg5L9D/hORCKASGPMXM/yT4FvPGNDNTHGfA9gjMkB8GxvqfGMY+OZSaslsMD7H0up49OkoNSxBPjUGPNEiYUiTx21XnljxJRXJZRb7L4L/T9U1YhWHyl1rJnAVSLSAIrmS26B/X+5yrPOdcACY0wacKjYJCc3AnONnQ8jXkQu82wjUERCTuunUKoS9AxFqaMYYzaIyP9hZ5ZzYEetvAfIBDqLyHIgDdvuAHZo6/c9B/3twBjP8huBD0TkOc82rj6NH0OpStFRUpWqIBHJMMaEVnUcSnmTVh8ppZQqoiUFpZRSRbSkoJRSqogmBaWUUkU0KSillCqiSUEppVQRTQpKKaWK/D8AmRdUfeYDdwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.reset_states()\n",
    "model.load_weights('../../saved_models/unet/unet_v4/model.hdf5')\n",
    "model.save('../../saved_models/unet/unet_v4/model_saved.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ai]",
   "language": "python",
   "name": "conda-env-ai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
